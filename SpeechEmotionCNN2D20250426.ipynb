{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/manhhad32/ParkingLot/blob/master/SpeechEmotionCNN2D20250426.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SKQ4bH7qMGrA"
      },
      "source": [
        "# Making the most of your colab subscription\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QMMqmdiYMkvi"
      },
      "source": [
        "## Faster GPUs\n",
        "\n",
        "<p>Users who have purchased one of Colab's paid plans have access to faster GPUs and more memory. You can upgrade your notebook's GPU settings in <code>Runtime &gt; Change runtime type</code> in the menu to select from several accelerator options, subject to availability.</p>\n",
        "<p>The free-of-charge version of Colab grants access to Nvidia's T4 GPUs subject to quota restrictions and availability.</p>\n",
        "\n",
        "You can see what GPU you've been assigned at any time by executing the following cell. If the execution result of running the code cell below is 'Not connected to a GPU', you can change the runtime by going to <code>Runtime &gt; Change runtime type</code> in the menu to enable a GPU accelerator, and then re-execute the code cell."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "23TOba33L4qf"
      },
      "outputs": [],
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gdown"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9pcfF4QE85q2",
        "outputId": "204f2747-5a39-47d7-d94c-3f1cde83d31d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gdown in /usr/local/lib/python3.11/dist-packages (5.2.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from gdown) (4.13.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from gdown) (3.18.0)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.11/dist-packages (from gdown) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from gdown) (4.67.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->gdown) (2.7)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->gdown) (4.13.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (2025.1.31)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (1.7.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import librosa\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Dropout, Flatten, Dense, BatchNormalization\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import glob\n",
        "from collections import Counter\n",
        "import zipfile\n",
        "from google.colab import drive\n",
        "import gdown"
      ],
      "metadata": {
        "id": "peOp0RDH82qc"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ví dụ link: https://drive.google.com/file/d/1AbCDEFGHIJKLMNOPQR/view?usp=sharing\n",
        "# Chỉ cần ID: \"1AbCDEFGHIJKLMNOPQR\"\n",
        "# https://drive.google.com/file/d/1BAKWfFtM3WqQQAa4mS5SMDAlKnPhV3mD/view?usp=sharing\n",
        "file_id = \"1BAKWfFtM3WqQQAa4mS5SMDAlKnPhV3mD\"\n",
        "output_zip = \"emotion_train.zip\"\n",
        "\n",
        "# Tạo link tải trực tiếp từ file_id\n",
        "gdown.download(f\"https://drive.google.com/uc?id={file_id}\", output_zip, quiet=False)\n",
        "\n",
        "# Bước 2: Giải nén file zip\n",
        "output_folder = \"emotion_train\"\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "with zipfile.ZipFile(output_zip, 'r') as zip_ref:\n",
        "    zip_ref.extractall(output_folder)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oj4yAzp888Xe",
        "outputId": "ac708283-3c1e-4d91-d03e-4bbef5c1131f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1BAKWfFtM3WqQQAa4mS5SMDAlKnPhV3mD\n",
            "From (redirected): https://drive.google.com/uc?id=1BAKWfFtM3WqQQAa4mS5SMDAlKnPhV3mD&confirm=t&uuid=f5a08942-cc23-461b-a763-55788b5668f5\n",
            "To: /content/emotion_train.zip\n",
            "100%|██████████| 1.16G/1.16G [00:15<00:00, 73.6MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_test_id = \"1OSG1oPq1ahQwEx7N3Wy3QG3j5mDkd6DJ\"\n",
        "output_test_zip = \"emotion_test.zip\"\n",
        "\n",
        "# Tạo link tải trực tiếp từ file_id\n",
        "gdown.download(f\"https://drive.google.com/uc?id={file_test_id}\", output_test_zip, quiet=False)\n",
        "\n",
        "# Bước 2: Giải nén file zip\n",
        "output_test_folder = \"emotion_test\"\n",
        "# The following line was changed\n",
        "os.makedirs(output_test_folder, exist_ok=True)\n",
        "# It was previously trying to create a directory with the same name as your zip file\n",
        "\n",
        "with zipfile.ZipFile(output_test_zip, 'r') as zip_ref:\n",
        "    zip_ref.extractall(output_test_folder)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KY3GdOXz8_bh",
        "outputId": "474ba2f9-d44a-4edb-8dec-42acaa4a1bbb"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1OSG1oPq1ahQwEx7N3Wy3QG3j5mDkd6DJ\n",
            "From (redirected): https://drive.google.com/uc?id=1OSG1oPq1ahQwEx7N3Wy3QG3j5mDkd6DJ&confirm=t&uuid=7a9d73e3-ea1d-4077-8e37-523f778c7e7b\n",
            "To: /content/emotion_test.zip\n",
            "100%|██████████| 42.6M/42.6M [00:00<00:00, 54.7MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil # Import the shutil module at the top of your code\n",
        "folder_path = '/content/emotion_test/__MACOSX'  # Đường dẫn thư mục cần xóa\n",
        "\n",
        "# Kiểm tra thư mục có tồn tại không rồi xóa\n",
        "if os.path.exists(folder_path):\n",
        "    shutil.rmtree(folder_path) # Now you can use shutil.rmtree\n",
        "    print(f\"✅ Đã xóa thư mục: {folder_path}\")\n",
        "else:\n",
        "    print(f\"⚠️ Thư mục không tồn tại: {folder_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EaoBhyKG9DTa",
        "outputId": "35c256c2-3ba4-462b-9205-f571de0f220e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Đã xóa thư mục: /content/emotion_test/__MACOSX\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Danh sách cảm xúc từ VNEMOS\n",
        "EMOTIONS = ['Angry', 'Happy', 'Sad', 'Neutral', 'Disgusted', 'Fearful', 'Suprised']\n",
        "NUM_CLASSES = len(EMOTIONS)\n",
        "\n",
        "# Hàm thêm nhiễu\n",
        "def add_noise(audio, noise_factor=0.005):\n",
        "    noise = np.random.randn(len(audio))\n",
        "    return audio + noise_factor * noise\n",
        "\n",
        "# Hàm thay đổi cao độ\n",
        "def pitch_shift(audio, sr, n_steps=1.5):\n",
        "    return librosa.effects.pitch_shift(audio, sr=sr, n_steps=n_steps)\n",
        "\n",
        "# Hàm kéo giãn thời gian\n",
        "def time_stretch(audio, rate=1.05):\n",
        "    return librosa.effects.time_stretch(audio, rate=rate)\n",
        "\n",
        "# Hàm dịch chuyển thời gian\n",
        "def time_shift(audio, shift_max=0.2, sr=16000):\n",
        "    shift = int(np.random.uniform(-shift_max, shift_max) * sr)\n",
        "    return np.roll(audio, shift)\n",
        "\n",
        "# Trích xuất MFCC với nhiều loại augmentation\n",
        "def extract_mfcc(audio_path, sample_rate=16000, duration=5, n_mfcc=26, n_frames=157, augment_type='normal'):\n",
        "    audio, sr = librosa.load(audio_path, sr=sample_rate)\n",
        "    target_length = sample_rate * duration\n",
        "\n",
        "    # Chuẩn hóa độ dài\n",
        "    if len(audio) < target_length:\n",
        "        audio = np.pad(audio, (0, target_length - len(audio)), mode='constant')\n",
        "    else:\n",
        "        audio = audio[:target_length]\n",
        "\n",
        "    # Áp dụng augmentation theo loại\n",
        "    if augment_type == 'noise':\n",
        "        audio = add_noise(audio)\n",
        "    elif augment_type == 'pitch':\n",
        "        audio = pitch_shift(audio, sr)\n",
        "    elif augment_type == 'stretch':\n",
        "        audio = time_stretch(audio)\n",
        "    elif augment_type == 'shift':\n",
        "        audio = time_shift(audio)\n",
        "    # 'normal' thì giữ nguyên\n",
        "\n",
        "    hop_length = target_length // (n_frames - 1)\n",
        "    mfcc = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=n_mfcc, hop_length=hop_length, n_fft=2048)\n",
        "    if mfcc.shape[1] > n_frames:\n",
        "        mfcc = mfcc[:, :n_frames]\n",
        "    elif mfcc.shape[1] < n_frames:\n",
        "        mfcc = np.pad(mfcc, ((0, 0), (0, n_frames - mfcc.shape[1])), mode='constant')\n",
        "\n",
        "    return np.expand_dims(mfcc, axis=-1)\n",
        "\n",
        "# Chuẩn bị dữ liệu với ánh xạ nhãn từ thư mục\n",
        "def prepare_training_data(audio_files, emotion_map):\n",
        "    X, y = [], []\n",
        "    augment_types = ['normal', 'noise', 'pitch', 'stretch', 'shift']\n",
        "\n",
        "    for audio_path in audio_files:\n",
        "        folder_name = os.path.basename(os.path.dirname(audio_path))\n",
        "        emotion_idx = emotion_map.get(folder_name, -1)\n",
        "        if emotion_idx == -1:\n",
        "            print(f\"Warning: {audio_path} không thuộc danh sách cảm xúc, bỏ qua.\")\n",
        "            continue\n",
        "\n",
        "        for aug_type in augment_types:\n",
        "            mfcc = extract_mfcc(str(audio_path), augment_type=aug_type)\n",
        "            X.append(mfcc)\n",
        "            y.append(emotion_idx)\n",
        "\n",
        "    X = np.array(X)\n",
        "    y = to_categorical(y, num_classes=NUM_CLASSES)\n",
        "    print(f\"Dataset shape: X={X.shape}, y={y.shape}\")\n",
        "    return X, y\n",
        "\n",
        "# Xây dựng mô hình CNN cải tiến\n",
        "def build_cnn_2d(input_shape=(26, 157, 1)):\n",
        "    model = Sequential([\n",
        "        Input(shape=input_shape),\n",
        "        Conv2D(32, (3, 3), activation='relu', padding='same', kernel_regularizer=l2(0.001)),\n",
        "        BatchNormalization(),\n",
        "        Conv2D(32, (3, 3), activation='relu', padding='same', kernel_regularizer=l2(0.001)),\n",
        "        BatchNormalization(),\n",
        "        MaxPooling2D((2, 2)),\n",
        "        Dropout(0.25),\n",
        "\n",
        "        Conv2D(64, (3, 3), activation='relu', padding='same', kernel_regularizer=l2(0.001)),\n",
        "        BatchNormalization(),\n",
        "        Conv2D(64, (3, 3), activation='relu', padding='same', kernel_regularizer=l2(0.001)),\n",
        "        BatchNormalization(),\n",
        "        MaxPooling2D((2, 2)),\n",
        "        Dropout(0.25),\n",
        "\n",
        "        Conv2D(128, (3, 3), activation='relu', padding='same', kernel_regularizer=l2(0.001)),\n",
        "        BatchNormalization(),\n",
        "        MaxPooling2D((2, 2)),\n",
        "        Dropout(0.25),\n",
        "\n",
        "        Flatten(),\n",
        "        Dense(256, activation='relu', kernel_regularizer=l2(0.001)),\n",
        "        Dropout(0.4),\n",
        "        Dense(NUM_CLASSES, activation='softmax')\n",
        "    ])\n",
        "    model.summary()\n",
        "    return model\n",
        "\n",
        "# Huấn luyện và đánh giá\n",
        "def train_and_evaluate_model(model, X, y, epochs=200, batch_size=16, checkpoint_path='best_model.h5'):\n",
        "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "    print(f\"Train shape: {X_train.shape}, Val shape: {X_val.shape}\")\n",
        "\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
        "                  loss=tf.keras.losses.CategoricalCrossentropy(label_smoothing=0.1),\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    early_stopping = EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True)\n",
        "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=10, min_lr=0.00001)\n",
        "    checkpoint = ModelCheckpoint(checkpoint_path, monitor='val_loss', save_best_only=True, mode='min', verbose=1)\n",
        "\n",
        "    history = model.fit(X_train, y_train,\n",
        "                        validation_data=(X_val, y_val),\n",
        "                        epochs=epochs,\n",
        "                        batch_size=batch_size,\n",
        "                        callbacks=[early_stopping, reduce_lr, checkpoint],\n",
        "                        verbose=1)\n",
        "\n",
        "    val_loss, val_accuracy = model.evaluate(X_val, y_val, verbose=0)\n",
        "    print(f\"\\nĐánh giá trên tập kiểm tra:\")\n",
        "    print(f\" - Loss: {val_loss:.4f}\")\n",
        "    print(f\" - Accuracy: {val_accuracy:.4f}\")\n",
        "    return model, history\n",
        "\n",
        "# Dự đoán trực tiếp bằng CNN\n",
        "def predict_emotion(audio_path, model):\n",
        "    mfcc = extract_mfcc(audio_path, augment_type='normal')\n",
        "    mfcc = np.expand_dims(mfcc, axis=0)\n",
        "    prediction = model.predict(mfcc, verbose=0)\n",
        "    predicted_emotion_idx = np.argmax(prediction, axis=1)[0]\n",
        "    return EMOTIONS[predicted_emotion_idx]\n",
        "\n",
        "# Vẽ biểu đồ Loss\n",
        "def plot_loss_history(history):\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(history.history['loss'], label='Train Loss')\n",
        "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "    plt.title('Training and Validation Loss Over Epochs')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "rBmTgCTB9GYd"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Main\n",
        "if __name__ == \"__main__\":\n",
        "    # Mount Google Drive (nếu dùng Colab)\n",
        "    #from google.colab import drive\n",
        "\n",
        "    # Đường dẫn tới dữ liệu\n",
        "    root_folder = \"/content/emotion_train/Emotions\"\n",
        "    folders = [f for f in glob.glob(os.path.join(root_folder, \"*\")) if os.path.isdir(f)]\n",
        "    all_files = []\n",
        "    for folder in folders:\n",
        "        all_files.extend(glob.glob(os.path.join(folder, \"**\", \"*.wav\"), recursive=True))\n",
        "\n",
        "    # Kiểm tra phân bố nhãn\n",
        "    emotion_map = {'Angry': 0, 'Happy': 1, 'Sad': 2, 'Neutral': 3, 'Disgusted': 4, 'Fearful': 5, 'Suprised': 6}\n",
        "    y_raw = [emotion_map.get(os.path.basename(os.path.dirname(f)), -1) for f in all_files]\n",
        "    print(\"Phân bố nhãn gốc:\", Counter([EMOTIONS[i] for i in y_raw if i != -1]))\n",
        "\n",
        "    # Chuẩn bị dữ liệu\n",
        "    X, y = prepare_training_data(all_files, emotion_map)\n",
        "\n",
        "    # Xây dựng và huấn luyện mô hình\n",
        "    cnn_model = build_cnn_2d(input_shape=(26, 157, 1))\n",
        "    cnn_model, history = train_and_evaluate_model(cnn_model, X, y,\n",
        "                                                  epochs=200,\n",
        "                                                  batch_size=16,\n",
        "                                                  checkpoint_path='best_cnn_2d_vnemos.h5')\n",
        "\n",
        "    # Lưu mô hình cuối cùng (tùy chọn)\n",
        "    cnn_model.save('final_cnn_2d_vnemos.h5')\n",
        "\n",
        "    # Vẽ biểu đồ Loss\n",
        "    plot_loss_history(history)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "tpBsLKAL9JhS",
        "outputId": "feaa4742-6b48-4301-91e9-cfd41369f24c"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Phân bố nhãn gốc: Counter({'Sad': 2137, 'Angry': 2116, 'Happy': 2105, 'Fearful': 1986, 'Disgusted': 1795, 'Neutral': 1755, 'Suprised': 557})\n",
            "Dataset shape: X=(62255, 26, 157, 1), y=(62255, 7)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m157\u001b[0m, \u001b[38;5;34m32\u001b[0m)    │           \u001b[38;5;34m320\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m157\u001b[0m, \u001b[38;5;34m32\u001b[0m)    │           \u001b[38;5;34m128\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m157\u001b[0m, \u001b[38;5;34m32\u001b[0m)    │         \u001b[38;5;34m9,248\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m157\u001b[0m, \u001b[38;5;34m32\u001b[0m)    │           \u001b[38;5;34m128\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m78\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m78\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m78\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m18,496\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m78\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │           \u001b[38;5;34m256\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m78\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m36,928\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_3           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m78\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │           \u001b[38;5;34m256\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m39\u001b[0m, \u001b[38;5;34m64\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m39\u001b[0m, \u001b[38;5;34m64\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m39\u001b[0m, \u001b[38;5;34m128\u001b[0m)     │        \u001b[38;5;34m73,856\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_4           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m39\u001b[0m, \u001b[38;5;34m128\u001b[0m)     │           \u001b[38;5;34m512\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m19\u001b[0m, \u001b[38;5;34m128\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m19\u001b[0m, \u001b[38;5;34m128\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7296\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │     \u001b[38;5;34m1,868,032\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)              │         \u001b[38;5;34m1,799\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">157</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">157</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">157</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">9,248</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">157</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">78</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">78</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">78</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">78</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">78</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_3           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">78</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">39</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">39</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">39</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_4           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">39</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7296</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,868,032</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,799</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,009,959\u001b[0m (7.67 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,009,959</span> (7.67 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,009,319\u001b[0m (7.66 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,009,319</span> (7.66 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m640\u001b[0m (2.50 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">640</span> (2.50 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train shape: (49804, 26, 157, 1), Val shape: (12451, 26, 157, 1)\n",
            "Epoch 1/200\n",
            "\u001b[1m3113/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3187 - loss: 2.5097\n",
            "Epoch 1: val_loss improved from inf to 1.93310, saving model to best_cnn_2d_vnemos.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m3113/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 8ms/step - accuracy: 0.3187 - loss: 2.5096 - val_accuracy: 0.5131 - val_loss: 1.9331 - learning_rate: 1.0000e-04\n",
            "Epoch 2/200\n",
            "\u001b[1m3109/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5020 - loss: 1.9086\n",
            "Epoch 2: val_loss improved from 1.93310 to 1.64179, saving model to best_cnn_2d_vnemos.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m3113/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 5ms/step - accuracy: 0.5020 - loss: 1.9085 - val_accuracy: 0.5898 - val_loss: 1.6418 - learning_rate: 1.0000e-04\n",
            "Epoch 3/200\n",
            "\u001b[1m3102/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5640 - loss: 1.6609\n",
            "Epoch 3: val_loss improved from 1.64179 to 1.44400, saving model to best_cnn_2d_vnemos.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m3113/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 5ms/step - accuracy: 0.5640 - loss: 1.6608 - val_accuracy: 0.6510 - val_loss: 1.4440 - learning_rate: 1.0000e-04\n",
            "Epoch 4/200\n",
            "\u001b[1m3104/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6068 - loss: 1.5203\n",
            "Epoch 4: val_loss improved from 1.44400 to 1.37234, saving model to best_cnn_2d_vnemos.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m3113/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - accuracy: 0.6068 - loss: 1.5202 - val_accuracy: 0.6739 - val_loss: 1.3723 - learning_rate: 1.0000e-04\n",
            "Epoch 5/200\n",
            "\u001b[1m3108/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6415 - loss: 1.4318\n",
            "Epoch 5: val_loss improved from 1.37234 to 1.28488, saving model to best_cnn_2d_vnemos.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m3113/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5ms/step - accuracy: 0.6415 - loss: 1.4318 - val_accuracy: 0.7101 - val_loss: 1.2849 - learning_rate: 1.0000e-04\n",
            "Epoch 6/200\n",
            "\u001b[1m3110/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6723 - loss: 1.3608\n",
            "Epoch 6: val_loss improved from 1.28488 to 1.22845, saving model to best_cnn_2d_vnemos.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m3113/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - accuracy: 0.6723 - loss: 1.3608 - val_accuracy: 0.7378 - val_loss: 1.2285 - learning_rate: 1.0000e-04\n",
            "Epoch 7/200\n",
            "\u001b[1m3103/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7009 - loss: 1.3074\n",
            "Epoch 7: val_loss improved from 1.22845 to 1.17341, saving model to best_cnn_2d_vnemos.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m3113/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5ms/step - accuracy: 0.7009 - loss: 1.3074 - val_accuracy: 0.7563 - val_loss: 1.1734 - learning_rate: 1.0000e-04\n",
            "Epoch 8/200\n",
            "\u001b[1m3103/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7285 - loss: 1.2507\n",
            "Epoch 8: val_loss improved from 1.17341 to 1.14556, saving model to best_cnn_2d_vnemos.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m3113/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - accuracy: 0.7285 - loss: 1.2507 - val_accuracy: 0.7723 - val_loss: 1.1456 - learning_rate: 1.0000e-04\n",
            "Epoch 9/200\n",
            "\u001b[1m3110/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7491 - loss: 1.2054\n",
            "Epoch 9: val_loss improved from 1.14556 to 1.10323, saving model to best_cnn_2d_vnemos.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m3113/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5ms/step - accuracy: 0.7491 - loss: 1.2054 - val_accuracy: 0.7925 - val_loss: 1.1032 - learning_rate: 1.0000e-04\n",
            "Epoch 10/200\n",
            "\u001b[1m3105/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7654 - loss: 1.1736\n",
            "Epoch 10: val_loss did not improve from 1.10323\n",
            "\u001b[1m3113/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - accuracy: 0.7654 - loss: 1.1736 - val_accuracy: 0.7986 - val_loss: 1.1050 - learning_rate: 1.0000e-04\n",
            "Epoch 11/200\n",
            "\u001b[1m3112/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7838 - loss: 1.1458\n",
            "Epoch 11: val_loss improved from 1.10323 to 1.04382, saving model to best_cnn_2d_vnemos.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m3113/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - accuracy: 0.7838 - loss: 1.1458 - val_accuracy: 0.8303 - val_loss: 1.0438 - learning_rate: 1.0000e-04\n",
            "Epoch 12/200\n",
            "\u001b[1m3113/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8025 - loss: 1.1149\n",
            "Epoch 12: val_loss improved from 1.04382 to 1.01598, saving model to best_cnn_2d_vnemos.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m3113/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - accuracy: 0.8025 - loss: 1.1149 - val_accuracy: 0.8452 - val_loss: 1.0160 - learning_rate: 1.0000e-04\n",
            "Epoch 13/200\n",
            "\u001b[1m3113/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8184 - loss: 1.0870\n",
            "Epoch 13: val_loss improved from 1.01598 to 1.01225, saving model to best_cnn_2d_vnemos.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m3113/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - accuracy: 0.8184 - loss: 1.0870 - val_accuracy: 0.8510 - val_loss: 1.0123 - learning_rate: 1.0000e-04\n",
            "Epoch 14/200\n",
            "\u001b[1m3102/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8307 - loss: 1.0704\n",
            "Epoch 14: val_loss improved from 1.01225 to 0.98840, saving model to best_cnn_2d_vnemos.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m3113/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - accuracy: 0.8307 - loss: 1.0704 - val_accuracy: 0.8594 - val_loss: 0.9884 - learning_rate: 1.0000e-04\n",
            "Epoch 15/200\n",
            "\u001b[1m3110/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8412 - loss: 1.0513\n",
            "Epoch 15: val_loss improved from 0.98840 to 0.98636, saving model to best_cnn_2d_vnemos.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m3113/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5ms/step - accuracy: 0.8412 - loss: 1.0513 - val_accuracy: 0.8624 - val_loss: 0.9864 - learning_rate: 1.0000e-04\n",
            "Epoch 16/200\n",
            "\u001b[1m3109/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8510 - loss: 1.0363\n",
            "Epoch 16: val_loss improved from 0.98636 to 0.97532, saving model to best_cnn_2d_vnemos.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m3113/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - accuracy: 0.8510 - loss: 1.0363 - val_accuracy: 0.8694 - val_loss: 0.9753 - learning_rate: 1.0000e-04\n",
            "Epoch 17/200\n",
            "\u001b[1m3103/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8601 - loss: 1.0220\n",
            "Epoch 17: val_loss improved from 0.97532 to 0.94778, saving model to best_cnn_2d_vnemos.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m3113/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - accuracy: 0.8601 - loss: 1.0220 - val_accuracy: 0.8881 - val_loss: 0.9478 - learning_rate: 1.0000e-04\n",
            "Epoch 18/200\n",
            "\u001b[1m3112/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8699 - loss: 1.0052\n",
            "Epoch 18: val_loss improved from 0.94778 to 0.94555, saving model to best_cnn_2d_vnemos.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m3113/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - accuracy: 0.8699 - loss: 1.0052 - val_accuracy: 0.8888 - val_loss: 0.9455 - learning_rate: 1.0000e-04\n",
            "Epoch 19/200\n",
            "\u001b[1m3107/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8762 - loss: 0.9923\n",
            "Epoch 19: val_loss improved from 0.94555 to 0.92794, saving model to best_cnn_2d_vnemos.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m3113/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - accuracy: 0.8762 - loss: 0.9923 - val_accuracy: 0.8974 - val_loss: 0.9279 - learning_rate: 1.0000e-04\n",
            "Epoch 20/200\n",
            "\u001b[1m3101/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8824 - loss: 0.9871\n",
            "Epoch 20: val_loss did not improve from 0.92794\n",
            "\u001b[1m3113/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - accuracy: 0.8824 - loss: 0.9871 - val_accuracy: 0.9003 - val_loss: 0.9282 - learning_rate: 1.0000e-04\n",
            "Epoch 21/200\n",
            "\u001b[1m3103/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8855 - loss: 0.9776\n",
            "Epoch 21: val_loss improved from 0.92794 to 0.91653, saving model to best_cnn_2d_vnemos.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m3113/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - accuracy: 0.8855 - loss: 0.9776 - val_accuracy: 0.9043 - val_loss: 0.9165 - learning_rate: 1.0000e-04\n",
            "Epoch 22/200\n",
            "\u001b[1m3104/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8928 - loss: 0.9662\n",
            "Epoch 22: val_loss improved from 0.91653 to 0.90657, saving model to best_cnn_2d_vnemos.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m3113/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - accuracy: 0.8928 - loss: 0.9662 - val_accuracy: 0.9097 - val_loss: 0.9066 - learning_rate: 1.0000e-04\n",
            "Epoch 23/200\n",
            "\u001b[1m3110/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8959 - loss: 0.9595\n",
            "Epoch 23: val_loss improved from 0.90657 to 0.90362, saving model to best_cnn_2d_vnemos.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m3113/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - accuracy: 0.8958 - loss: 0.9595 - val_accuracy: 0.9121 - val_loss: 0.9036 - learning_rate: 1.0000e-04\n",
            "Epoch 24/200\n",
            "\u001b[1m3102/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8964 - loss: 0.9569\n",
            "Epoch 24: val_loss improved from 0.90362 to 0.89438, saving model to best_cnn_2d_vnemos.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m3113/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5ms/step - accuracy: 0.8964 - loss: 0.9569 - val_accuracy: 0.9168 - val_loss: 0.8944 - learning_rate: 1.0000e-04\n",
            "Epoch 25/200\n",
            "\u001b[1m3104/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8977 - loss: 0.9517\n",
            "Epoch 25: val_loss improved from 0.89438 to 0.89192, saving model to best_cnn_2d_vnemos.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m3113/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - accuracy: 0.8976 - loss: 0.9517 - val_accuracy: 0.9185 - val_loss: 0.8919 - learning_rate: 1.0000e-04\n",
            "Epoch 26/200\n",
            "\u001b[1m3109/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9031 - loss: 0.9466\n",
            "Epoch 26: val_loss improved from 0.89192 to 0.89109, saving model to best_cnn_2d_vnemos.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m3113/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - accuracy: 0.9031 - loss: 0.9467 - val_accuracy: 0.9148 - val_loss: 0.8911 - learning_rate: 1.0000e-04\n",
            "Epoch 27/200\n",
            "\u001b[1m3103/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9064 - loss: 0.9384\n",
            "Epoch 27: val_loss improved from 0.89109 to 0.88454, saving model to best_cnn_2d_vnemos.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m3113/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5ms/step - accuracy: 0.9064 - loss: 0.9384 - val_accuracy: 0.9255 - val_loss: 0.8845 - learning_rate: 1.0000e-04\n",
            "Epoch 28/200\n",
            "\u001b[1m3108/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9099 - loss: 0.9327\n",
            "Epoch 28: val_loss improved from 0.88454 to 0.87863, saving model to best_cnn_2d_vnemos.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m3113/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - accuracy: 0.9099 - loss: 0.9327 - val_accuracy: 0.9230 - val_loss: 0.8786 - learning_rate: 1.0000e-04\n",
            "Epoch 29/200\n",
            "\u001b[1m3112/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9093 - loss: 0.9311\n",
            "Epoch 29: val_loss did not improve from 0.87863\n",
            "\u001b[1m3113/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - accuracy: 0.9093 - loss: 0.9311 - val_accuracy: 0.9190 - val_loss: 0.8829 - learning_rate: 1.0000e-04\n",
            "Epoch 30/200\n",
            "\u001b[1m3110/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9114 - loss: 0.9280\n",
            "Epoch 30: val_loss did not improve from 0.87863\n",
            "\u001b[1m3113/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - accuracy: 0.9114 - loss: 0.9280 - val_accuracy: 0.9169 - val_loss: 0.8901 - learning_rate: 1.0000e-04\n",
            "Epoch 31/200\n",
            "\u001b[1m3104/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9146 - loss: 0.9210\n",
            "Epoch 31: val_loss improved from 0.87863 to 0.87764, saving model to best_cnn_2d_vnemos.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m3113/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - accuracy: 0.9146 - loss: 0.9210 - val_accuracy: 0.9190 - val_loss: 0.8776 - learning_rate: 1.0000e-04\n",
            "Epoch 32/200\n",
            "\u001b[1m3108/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9160 - loss: 0.9184\n",
            "Epoch 32: val_loss improved from 0.87764 to 0.87571, saving model to best_cnn_2d_vnemos.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m3113/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - accuracy: 0.9160 - loss: 0.9184 - val_accuracy: 0.9226 - val_loss: 0.8757 - learning_rate: 1.0000e-04\n",
            "Epoch 33/200\n",
            "\u001b[1m3103/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9134 - loss: 0.9181\n",
            "Epoch 33: val_loss improved from 0.87571 to 0.87078, saving model to best_cnn_2d_vnemos.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m3113/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5ms/step - accuracy: 0.9134 - loss: 0.9181 - val_accuracy: 0.9277 - val_loss: 0.8708 - learning_rate: 1.0000e-04\n",
            "Epoch 34/200\n",
            "\u001b[1m3101/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9181 - loss: 0.9143\n",
            "Epoch 34: val_loss improved from 0.87078 to 0.86446, saving model to best_cnn_2d_vnemos.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m3113/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5ms/step - accuracy: 0.9181 - loss: 0.9143 - val_accuracy: 0.9284 - val_loss: 0.8645 - learning_rate: 1.0000e-04\n",
            "Epoch 35/200\n",
            "\u001b[1m3103/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9197 - loss: 0.9072\n",
            "Epoch 35: val_loss did not improve from 0.86446\n",
            "\u001b[1m3113/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - accuracy: 0.9197 - loss: 0.9072 - val_accuracy: 0.9179 - val_loss: 0.8843 - learning_rate: 1.0000e-04\n",
            "Epoch 36/200\n",
            "\u001b[1m3102/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9182 - loss: 0.9104\n",
            "Epoch 36: val_loss did not improve from 0.86446\n",
            "\u001b[1m3113/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - accuracy: 0.9182 - loss: 0.9104 - val_accuracy: 0.9255 - val_loss: 0.8709 - learning_rate: 1.0000e-04\n",
            "Epoch 37/200\n",
            "\u001b[1m3111/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9242 - loss: 0.9008\n",
            "Epoch 37: val_loss did not improve from 0.86446\n",
            "\u001b[1m3113/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - accuracy: 0.9242 - loss: 0.9009 - val_accuracy: 0.9159 - val_loss: 0.8800 - learning_rate: 1.0000e-04\n",
            "Epoch 38/200\n",
            "\u001b[1m3105/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9220 - loss: 0.9021\n",
            "Epoch 38: val_loss did not improve from 0.86446\n",
            "\u001b[1m3113/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5ms/step - accuracy: 0.9220 - loss: 0.9022 - val_accuracy: 0.9249 - val_loss: 0.8693 - learning_rate: 1.0000e-04\n",
            "Epoch 39/200\n",
            "\u001b[1m3113/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9213 - loss: 0.9023\n",
            "Epoch 39: val_loss improved from 0.86446 to 0.85915, saving model to best_cnn_2d_vnemos.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m3113/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5ms/step - accuracy: 0.9213 - loss: 0.9023 - val_accuracy: 0.9312 - val_loss: 0.8591 - learning_rate: 1.0000e-04\n",
            "Epoch 40/200\n",
            "\u001b[1m3103/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9241 - loss: 0.9001\n",
            "Epoch 40: val_loss did not improve from 0.85915\n",
            "\u001b[1m3113/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - accuracy: 0.9241 - loss: 0.9002 - val_accuracy: 0.9243 - val_loss: 0.8677 - learning_rate: 1.0000e-04\n",
            "Epoch 41/200\n",
            "\u001b[1m3109/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9234 - loss: 0.8989\n",
            "Epoch 41: val_loss improved from 0.85915 to 0.85529, saving model to best_cnn_2d_vnemos.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m3113/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5ms/step - accuracy: 0.9234 - loss: 0.8989 - val_accuracy: 0.9301 - val_loss: 0.8553 - learning_rate: 1.0000e-04\n",
            "Epoch 42/200\n",
            "\u001b[1m3112/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9246 - loss: 0.8945\n",
            "Epoch 42: val_loss did not improve from 0.85529\n",
            "\u001b[1m3113/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - accuracy: 0.9246 - loss: 0.8945 - val_accuracy: 0.9249 - val_loss: 0.8605 - learning_rate: 1.0000e-04\n",
            "Epoch 43/200\n",
            "\u001b[1m3106/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9239 - loss: 0.8949\n",
            "Epoch 43: val_loss improved from 0.85529 to 0.85431, saving model to best_cnn_2d_vnemos.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m3113/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - accuracy: 0.9239 - loss: 0.8949 - val_accuracy: 0.9297 - val_loss: 0.8543 - learning_rate: 1.0000e-04\n",
            "Epoch 44/200\n",
            "\u001b[1m3106/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9261 - loss: 0.8894\n",
            "Epoch 44: val_loss improved from 0.85431 to 0.85287, saving model to best_cnn_2d_vnemos.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m3113/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5ms/step - accuracy: 0.9261 - loss: 0.8894 - val_accuracy: 0.9319 - val_loss: 0.8529 - learning_rate: 1.0000e-04\n",
            "Epoch 45/200\n",
            "\u001b[1m3110/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9255 - loss: 0.8888\n",
            "Epoch 45: val_loss did not improve from 0.85287\n",
            "\u001b[1m3113/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - accuracy: 0.9255 - loss: 0.8888 - val_accuracy: 0.9280 - val_loss: 0.8567 - learning_rate: 1.0000e-04\n",
            "Epoch 46/200\n",
            "\u001b[1m3105/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9271 - loss: 0.8878\n",
            "Epoch 46: val_loss improved from 0.85287 to 0.84918, saving model to best_cnn_2d_vnemos.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m3113/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - accuracy: 0.9270 - loss: 0.8878 - val_accuracy: 0.9327 - val_loss: 0.8492 - learning_rate: 1.0000e-04\n",
            "Epoch 47/200\n",
            "\u001b[1m3109/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9281 - loss: 0.8873\n",
            "Epoch 47: val_loss did not improve from 0.84918\n",
            "\u001b[1m3113/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5ms/step - accuracy: 0.9280 - loss: 0.8873 - val_accuracy: 0.9270 - val_loss: 0.8552 - learning_rate: 1.0000e-04\n",
            "Epoch 48/200\n",
            "\u001b[1m3107/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9302 - loss: 0.8815\n",
            "Epoch 48: val_loss did not improve from 0.84918\n",
            "\u001b[1m3113/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - accuracy: 0.9301 - loss: 0.8815 - val_accuracy: 0.9228 - val_loss: 0.8631 - learning_rate: 1.0000e-04\n",
            "Epoch 49/200\n",
            "\u001b[1m3111/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9279 - loss: 0.8856\n",
            "Epoch 49: val_loss improved from 0.84918 to 0.84288, saving model to best_cnn_2d_vnemos.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m3113/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - accuracy: 0.9279 - loss: 0.8856 - val_accuracy: 0.9347 - val_loss: 0.8429 - learning_rate: 1.0000e-04\n",
            "Epoch 50/200\n",
            "\u001b[1m3103/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9270 - loss: 0.8866\n",
            "Epoch 50: val_loss improved from 0.84288 to 0.83995, saving model to best_cnn_2d_vnemos.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m3113/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - accuracy: 0.9270 - loss: 0.8866 - val_accuracy: 0.9339 - val_loss: 0.8400 - learning_rate: 1.0000e-04\n",
            "Epoch 51/200\n",
            "\u001b[1m3108/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9294 - loss: 0.8798\n",
            "Epoch 51: val_loss improved from 0.83995 to 0.83686, saving model to best_cnn_2d_vnemos.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m3113/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5ms/step - accuracy: 0.9293 - loss: 0.8798 - val_accuracy: 0.9387 - val_loss: 0.8369 - learning_rate: 1.0000e-04\n",
            "Epoch 52/200\n",
            "\u001b[1m3109/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9279 - loss: 0.8827\n",
            "Epoch 52: val_loss did not improve from 0.83686\n",
            "\u001b[1m3113/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - accuracy: 0.9279 - loss: 0.8827 - val_accuracy: 0.9302 - val_loss: 0.8517 - learning_rate: 1.0000e-04\n",
            "Epoch 53/200\n",
            "\u001b[1m3107/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9293 - loss: 0.8776\n",
            "Epoch 53: val_loss did not improve from 0.83686\n",
            "\u001b[1m3113/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - accuracy: 0.9293 - loss: 0.8776 - val_accuracy: 0.9312 - val_loss: 0.8456 - learning_rate: 1.0000e-04\n",
            "Epoch 54/200\n",
            "\u001b[1m3110/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9294 - loss: 0.8778\n",
            "Epoch 54: val_loss did not improve from 0.83686\n",
            "\u001b[1m3113/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - accuracy: 0.9294 - loss: 0.8778 - val_accuracy: 0.9326 - val_loss: 0.8414 - learning_rate: 1.0000e-04\n",
            "Epoch 55/200\n",
            "\u001b[1m3108/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9312 - loss: 0.8772\n",
            "Epoch 55: val_loss did not improve from 0.83686\n",
            "\u001b[1m3113/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - accuracy: 0.9312 - loss: 0.8772 - val_accuracy: 0.9330 - val_loss: 0.8443 - learning_rate: 1.0000e-04\n",
            "Epoch 56/200\n",
            "\u001b[1m3105/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9320 - loss: 0.8735\n",
            "Epoch 56: val_loss did not improve from 0.83686\n",
            "\u001b[1m3113/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5ms/step - accuracy: 0.9320 - loss: 0.8736 - val_accuracy: 0.9329 - val_loss: 0.8398 - learning_rate: 1.0000e-04\n",
            "Epoch 57/200\n",
            "\u001b[1m3106/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9332 - loss: 0.8719\n",
            "Epoch 57: val_loss did not improve from 0.83686\n",
            "\u001b[1m3113/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - accuracy: 0.9332 - loss: 0.8719 - val_accuracy: 0.9356 - val_loss: 0.8385 - learning_rate: 1.0000e-04\n",
            "Epoch 58/200\n",
            "\u001b[1m3113/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9310 - loss: 0.8738\n",
            "Epoch 58: val_loss improved from 0.83686 to 0.83569, saving model to best_cnn_2d_vnemos.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m3113/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5ms/step - accuracy: 0.9310 - loss: 0.8738 - val_accuracy: 0.9361 - val_loss: 0.8357 - learning_rate: 1.0000e-04\n",
            "Epoch 59/200\n",
            "\u001b[1m3107/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9332 - loss: 0.8700\n",
            "Epoch 59: val_loss improved from 0.83569 to 0.82991, saving model to best_cnn_2d_vnemos.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m3113/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5ms/step - accuracy: 0.9331 - loss: 0.8701 - val_accuracy: 0.9415 - val_loss: 0.8299 - learning_rate: 1.0000e-04\n",
            "Epoch 60/200\n",
            "\u001b[1m3110/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9327 - loss: 0.8723\n",
            "Epoch 60: val_loss did not improve from 0.82991\n",
            "\u001b[1m3113/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - accuracy: 0.9327 - loss: 0.8723 - val_accuracy: 0.9288 - val_loss: 0.8480 - learning_rate: 1.0000e-04\n",
            "Epoch 61/200\n",
            "\u001b[1m3110/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9311 - loss: 0.8704\n",
            "Epoch 61: val_loss improved from 0.82991 to 0.82736, saving model to best_cnn_2d_vnemos.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m3113/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5ms/step - accuracy: 0.9311 - loss: 0.8704 - val_accuracy: 0.9396 - val_loss: 0.8274 - learning_rate: 1.0000e-04\n",
            "Epoch 62/200\n",
            "\u001b[1m3111/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9315 - loss: 0.8726\n",
            "Epoch 62: val_loss did not improve from 0.82736\n",
            "\u001b[1m3113/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - accuracy: 0.9315 - loss: 0.8726 - val_accuracy: 0.9377 - val_loss: 0.8346 - learning_rate: 1.0000e-04\n",
            "Epoch 63/200\n",
            "\u001b[1m3103/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9323 - loss: 0.8689\n",
            "Epoch 63: val_loss did not improve from 0.82736\n",
            "\u001b[1m3113/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - accuracy: 0.9322 - loss: 0.8690 - val_accuracy: 0.9353 - val_loss: 0.8375 - learning_rate: 1.0000e-04\n",
            "Epoch 64/200\n",
            "\u001b[1m3104/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9316 - loss: 0.8717\n",
            "Epoch 64: val_loss did not improve from 0.82736\n",
            "\u001b[1m3113/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - accuracy: 0.9316 - loss: 0.8718 - val_accuracy: 0.9342 - val_loss: 0.8337 - learning_rate: 1.0000e-04\n",
            "Epoch 65/200\n",
            "\u001b[1m3106/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9317 - loss: 0.8705\n",
            "Epoch 65: val_loss did not improve from 0.82736\n",
            "\u001b[1m3113/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - accuracy: 0.9317 - loss: 0.8705 - val_accuracy: 0.9354 - val_loss: 0.8332 - learning_rate: 1.0000e-04\n",
            "Epoch 66/200\n",
            "\u001b[1m3102/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9345 - loss: 0.8667\n",
            "Epoch 66: val_loss did not improve from 0.82736\n",
            "\u001b[1m3113/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - accuracy: 0.9345 - loss: 0.8668 - val_accuracy: 0.9401 - val_loss: 0.8279 - learning_rate: 1.0000e-04\n",
            "Epoch 67/200\n",
            "\u001b[1m3113/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9339 - loss: 0.8690\n",
            "Epoch 67: val_loss did not improve from 0.82736\n",
            "\u001b[1m3113/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - accuracy: 0.9339 - loss: 0.8690 - val_accuracy: 0.9345 - val_loss: 0.8370 - learning_rate: 1.0000e-04\n",
            "Epoch 68/200\n",
            "\u001b[1m3112/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9336 - loss: 0.8656\n",
            "Epoch 68: val_loss improved from 0.82736 to 0.82351, saving model to best_cnn_2d_vnemos.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m3113/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - accuracy: 0.9336 - loss: 0.8656 - val_accuracy: 0.9407 - val_loss: 0.8235 - learning_rate: 1.0000e-04\n",
            "Epoch 69/200\n",
            "\u001b[1m3108/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9359 - loss: 0.8644\n",
            "Epoch 69: val_loss did not improve from 0.82351\n",
            "\u001b[1m3113/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - accuracy: 0.9359 - loss: 0.8645 - val_accuracy: 0.9366 - val_loss: 0.8330 - learning_rate: 1.0000e-04\n",
            "Epoch 70/200\n",
            "\u001b[1m3107/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9361 - loss: 0.8629\n",
            "Epoch 70: val_loss did not improve from 0.82351\n",
            "\u001b[1m3113/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - accuracy: 0.9361 - loss: 0.8629 - val_accuracy: 0.9338 - val_loss: 0.8408 - learning_rate: 1.0000e-04\n",
            "Epoch 71/200\n",
            "\u001b[1m3102/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9347 - loss: 0.8645\n",
            "Epoch 71: val_loss did not improve from 0.82351\n",
            "\u001b[1m3113/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - accuracy: 0.9347 - loss: 0.8645 - val_accuracy: 0.9383 - val_loss: 0.8284 - learning_rate: 1.0000e-04\n",
            "Epoch 72/200\n",
            "\u001b[1m3110/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9334 - loss: 0.8668\n",
            "Epoch 72: val_loss did not improve from 0.82351\n",
            "\u001b[1m3113/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - accuracy: 0.9334 - loss: 0.8668 - val_accuracy: 0.9385 - val_loss: 0.8290 - learning_rate: 1.0000e-04\n",
            "Epoch 73/200\n",
            "\u001b[1m3104/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9334 - loss: 0.8619\n",
            "Epoch 73: val_loss improved from 0.82351 to 0.82299, saving model to best_cnn_2d_vnemos.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m3113/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - accuracy: 0.9334 - loss: 0.8619 - val_accuracy: 0.9430 - val_loss: 0.8230 - learning_rate: 1.0000e-04\n",
            "Epoch 74/200\n",
            "\u001b[1m3101/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9358 - loss: 0.8604\n",
            "Epoch 74: val_loss improved from 0.82299 to 0.82248, saving model to best_cnn_2d_vnemos.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m3113/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - accuracy: 0.9358 - loss: 0.8604 - val_accuracy: 0.9413 - val_loss: 0.8225 - learning_rate: 1.0000e-04\n",
            "Epoch 75/200\n",
            "\u001b[1m3110/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9320 - loss: 0.8627\n",
            "Epoch 75: val_loss improved from 0.82248 to 0.82049, saving model to best_cnn_2d_vnemos.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m3113/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5ms/step - accuracy: 0.9320 - loss: 0.8627 - val_accuracy: 0.9433 - val_loss: 0.8205 - learning_rate: 1.0000e-04\n",
            "Epoch 76/200\n",
            "\u001b[1m3103/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9342 - loss: 0.8624\n",
            "Epoch 76: val_loss did not improve from 0.82049\n",
            "\u001b[1m3113/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - accuracy: 0.9342 - loss: 0.8625 - val_accuracy: 0.9394 - val_loss: 0.8260 - learning_rate: 1.0000e-04\n",
            "Epoch 77/200\n",
            "\u001b[1m3112/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9376 - loss: 0.8578\n",
            "Epoch 77: val_loss did not improve from 0.82049\n",
            "\u001b[1m3113/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5ms/step - accuracy: 0.9376 - loss: 0.8578 - val_accuracy: 0.9341 - val_loss: 0.8333 - learning_rate: 1.0000e-04\n",
            "Epoch 78/200\n",
            "\u001b[1m3108/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9383 - loss: 0.8552\n",
            "Epoch 78: val_loss did not improve from 0.82049\n",
            "\u001b[1m3113/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - accuracy: 0.9383 - loss: 0.8552 - val_accuracy: 0.9397 - val_loss: 0.8244 - learning_rate: 1.0000e-04\n",
            "Epoch 79/200\n",
            "\u001b[1m3112/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9360 - loss: 0.8574\n",
            "Epoch 79: val_loss improved from 0.82049 to 0.81810, saving model to best_cnn_2d_vnemos.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m3113/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5ms/step - accuracy: 0.9360 - loss: 0.8574 - val_accuracy: 0.9415 - val_loss: 0.8181 - learning_rate: 1.0000e-04\n",
            "Epoch 80/200\n",
            "\u001b[1m3100/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9385 - loss: 0.8580\n",
            "Epoch 80: val_loss did not improve from 0.81810\n",
            "\u001b[1m3113/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - accuracy: 0.9385 - loss: 0.8580 - val_accuracy: 0.9400 - val_loss: 0.8222 - learning_rate: 1.0000e-04\n",
            "Epoch 81/200\n",
            "\u001b[1m3109/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9393 - loss: 0.8549\n",
            "Epoch 81: val_loss did not improve from 0.81810\n",
            "\u001b[1m3113/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5ms/step - accuracy: 0.9393 - loss: 0.8549 - val_accuracy: 0.9374 - val_loss: 0.8305 - learning_rate: 1.0000e-04\n",
            "Epoch 82/200\n",
            "\u001b[1m3107/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9368 - loss: 0.8565\n",
            "Epoch 82: val_loss did not improve from 0.81810\n",
            "\u001b[1m3113/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5ms/step - accuracy: 0.9368 - loss: 0.8565 - val_accuracy: 0.9394 - val_loss: 0.8237 - learning_rate: 1.0000e-04\n",
            "Epoch 83/200\n",
            "\u001b[1m3107/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9371 - loss: 0.8556\n",
            "Epoch 83: val_loss improved from 0.81810 to 0.81408, saving model to best_cnn_2d_vnemos.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m3113/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5ms/step - accuracy: 0.9371 - loss: 0.8556 - val_accuracy: 0.9454 - val_loss: 0.8141 - learning_rate: 1.0000e-04\n",
            "Epoch 84/200\n",
            "\u001b[1m3103/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9392 - loss: 0.8542\n",
            "Epoch 84: val_loss did not improve from 0.81408\n",
            "\u001b[1m3113/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - accuracy: 0.9392 - loss: 0.8542 - val_accuracy: 0.9373 - val_loss: 0.8228 - learning_rate: 1.0000e-04\n",
            "Epoch 85/200\n",
            "\u001b[1m3102/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9375 - loss: 0.8559\n",
            "Epoch 85: val_loss did not improve from 0.81408\n",
            "\u001b[1m3113/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5ms/step - accuracy: 0.9375 - loss: 0.8559 - val_accuracy: 0.9350 - val_loss: 0.8265 - learning_rate: 1.0000e-04\n",
            "Epoch 86/200\n",
            "\u001b[1m3101/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9367 - loss: 0.8576\n",
            "Epoch 86: val_loss did not improve from 0.81408\n",
            "\u001b[1m3113/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - accuracy: 0.9367 - loss: 0.8577 - val_accuracy: 0.9403 - val_loss: 0.8236 - learning_rate: 1.0000e-04\n",
            "Epoch 87/200\n",
            "\u001b[1m3105/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9372 - loss: 0.8564\n",
            "Epoch 87: val_loss did not improve from 0.81408\n",
            "\u001b[1m3113/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5ms/step - accuracy: 0.9372 - loss: 0.8564 - val_accuracy: 0.9415 - val_loss: 0.8151 - learning_rate: 1.0000e-04\n",
            "Epoch 88/200\n",
            "\u001b[1m3100/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9395 - loss: 0.8528\n",
            "Epoch 88: val_loss did not improve from 0.81408\n",
            "\u001b[1m3113/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5ms/step - accuracy: 0.9395 - loss: 0.8529 - val_accuracy: 0.9377 - val_loss: 0.8247 - learning_rate: 1.0000e-04\n",
            "Epoch 89/200\n",
            "\u001b[1m3106/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9394 - loss: 0.8504\n",
            "Epoch 89: val_loss did not improve from 0.81408\n",
            "\u001b[1m3113/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - accuracy: 0.9394 - loss: 0.8504 - val_accuracy: 0.9398 - val_loss: 0.8231 - learning_rate: 1.0000e-04\n",
            "Epoch 90/200\n",
            "\u001b[1m3108/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9372 - loss: 0.8521\n",
            "Epoch 90: val_loss did not improve from 0.81408\n",
            "\u001b[1m3113/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - accuracy: 0.9372 - loss: 0.8522 - val_accuracy: 0.9439 - val_loss: 0.8142 - learning_rate: 1.0000e-04\n",
            "Epoch 91/200\n",
            "\u001b[1m3105/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9371 - loss: 0.8550\n",
            "Epoch 91: val_loss did not improve from 0.81408\n",
            "\u001b[1m3113/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - accuracy: 0.9371 - loss: 0.8550 - val_accuracy: 0.9435 - val_loss: 0.8177 - learning_rate: 1.0000e-04\n",
            "Epoch 92/200\n",
            "\u001b[1m3103/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9384 - loss: 0.8517\n",
            "Epoch 92: val_loss did not improve from 0.81408\n",
            "\u001b[1m3113/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - accuracy: 0.9384 - loss: 0.8517 - val_accuracy: 0.9361 - val_loss: 0.8284 - learning_rate: 1.0000e-04\n",
            "Epoch 93/200\n",
            "\u001b[1m3104/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9418 - loss: 0.8481\n",
            "Epoch 93: val_loss did not improve from 0.81408\n",
            "\u001b[1m3113/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - accuracy: 0.9418 - loss: 0.8481 - val_accuracy: 0.9406 - val_loss: 0.8231 - learning_rate: 1.0000e-04\n",
            "Epoch 94/200\n",
            "\u001b[1m3105/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9533 - loss: 0.8255\n",
            "Epoch 94: val_loss improved from 0.81408 to 0.77457, saving model to best_cnn_2d_vnemos.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m3113/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5ms/step - accuracy: 0.9533 - loss: 0.8255 - val_accuracy: 0.9592 - val_loss: 0.7746 - learning_rate: 2.0000e-05\n",
            "Epoch 95/200\n",
            "\u001b[1m3112/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9632 - loss: 0.7986\n",
            "Epoch 95: val_loss improved from 0.77457 to 0.76661, saving model to best_cnn_2d_vnemos.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m3113/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5ms/step - accuracy: 0.9632 - loss: 0.7986 - val_accuracy: 0.9580 - val_loss: 0.7666 - learning_rate: 2.0000e-05\n",
            "Epoch 96/200\n",
            "\u001b[1m3108/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9673 - loss: 0.7803\n",
            "Epoch 96: val_loss improved from 0.76661 to 0.75328, saving model to best_cnn_2d_vnemos.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m3113/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - accuracy: 0.9673 - loss: 0.7803 - val_accuracy: 0.9607 - val_loss: 0.7533 - learning_rate: 2.0000e-05\n",
            "Epoch 97/200\n",
            "\u001b[1m3113/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9698 - loss: 0.7684\n",
            "Epoch 97: val_loss improved from 0.75328 to 0.74428, saving model to best_cnn_2d_vnemos.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m3113/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5ms/step - accuracy: 0.9698 - loss: 0.7684 - val_accuracy: 0.9623 - val_loss: 0.7443 - learning_rate: 2.0000e-05\n",
            "Epoch 98/200\n",
            "\u001b[1m3112/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9715 - loss: 0.7574\n",
            "Epoch 98: val_loss improved from 0.74428 to 0.73804, saving model to best_cnn_2d_vnemos.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m3113/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5ms/step - accuracy: 0.9715 - loss: 0.7574 - val_accuracy: 0.9611 - val_loss: 0.7380 - learning_rate: 2.0000e-05\n",
            "Epoch 99/200\n",
            "\u001b[1m3102/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9733 - loss: 0.7489\n",
            "Epoch 99: val_loss improved from 0.73804 to 0.73428, saving model to best_cnn_2d_vnemos.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m3113/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5ms/step - accuracy: 0.9733 - loss: 0.7489 - val_accuracy: 0.9605 - val_loss: 0.7343 - learning_rate: 2.0000e-05\n",
            "Epoch 100/200\n",
            "\u001b[1m3113/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9745 - loss: 0.7408\n",
            "Epoch 100: val_loss improved from 0.73428 to 0.72331, saving model to best_cnn_2d_vnemos.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m3113/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5ms/step - accuracy: 0.9745 - loss: 0.7408 - val_accuracy: 0.9643 - val_loss: 0.7233 - learning_rate: 2.0000e-05\n",
            "Epoch 101/200\n",
            "\u001b[1m3104/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9749 - loss: 0.7339\n",
            "Epoch 101: val_loss improved from 0.72331 to 0.71691, saving model to best_cnn_2d_vnemos.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m3113/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - accuracy: 0.9749 - loss: 0.7339 - val_accuracy: 0.9657 - val_loss: 0.7169 - learning_rate: 2.0000e-05\n",
            "Epoch 102/200\n",
            "\u001b[1m3104/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9757 - loss: 0.7269\n",
            "Epoch 102: val_loss improved from 0.71691 to 0.71273, saving model to best_cnn_2d_vnemos.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m3113/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5ms/step - accuracy: 0.9757 - loss: 0.7269 - val_accuracy: 0.9652 - val_loss: 0.7127 - learning_rate: 2.0000e-05\n",
            "Epoch 103/200\n",
            "\u001b[1m3113/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9756 - loss: 0.7225\n",
            "Epoch 103: val_loss improved from 0.71273 to 0.70643, saving model to best_cnn_2d_vnemos.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m3113/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5ms/step - accuracy: 0.9756 - loss: 0.7225 - val_accuracy: 0.9661 - val_loss: 0.7064 - learning_rate: 2.0000e-05\n",
            "Epoch 104/200\n",
            "\u001b[1m3108/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9773 - loss: 0.7156\n",
            "Epoch 104: val_loss improved from 0.70643 to 0.70406, saving model to best_cnn_2d_vnemos.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m3113/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5ms/step - accuracy: 0.9773 - loss: 0.7156 - val_accuracy: 0.9654 - val_loss: 0.7041 - learning_rate: 2.0000e-05\n",
            "Epoch 105/200\n",
            "\u001b[1m3110/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9770 - loss: 0.7104\n",
            "Epoch 105: val_loss improved from 0.70406 to 0.69901, saving model to best_cnn_2d_vnemos.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m3113/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5ms/step - accuracy: 0.9770 - loss: 0.7104 - val_accuracy: 0.9660 - val_loss: 0.6990 - learning_rate: 2.0000e-05\n",
            "Epoch 106/200\n",
            "\u001b[1m3109/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9779 - loss: 0.7060\n",
            "Epoch 106: val_loss improved from 0.69901 to 0.69758, saving model to best_cnn_2d_vnemos.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m3113/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5ms/step - accuracy: 0.9779 - loss: 0.7060 - val_accuracy: 0.9642 - val_loss: 0.6976 - learning_rate: 2.0000e-05\n",
            "Epoch 107/200\n",
            "\u001b[1m3108/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9790 - loss: 0.7014\n",
            "Epoch 107: val_loss improved from 0.69758 to 0.69169, saving model to best_cnn_2d_vnemos.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m3113/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5ms/step - accuracy: 0.9790 - loss: 0.7014 - val_accuracy: 0.9663 - val_loss: 0.6917 - learning_rate: 2.0000e-05\n",
            "Epoch 108/200\n",
            "\u001b[1m3104/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9810 - loss: 0.6952\n",
            "Epoch 108: val_loss improved from 0.69169 to 0.68584, saving model to best_cnn_2d_vnemos.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m3113/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5ms/step - accuracy: 0.9810 - loss: 0.6952 - val_accuracy: 0.9672 - val_loss: 0.6858 - learning_rate: 2.0000e-05\n",
            "Epoch 109/200\n",
            "\u001b[1m3102/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9793 - loss: 0.6933\n",
            "Epoch 109: val_loss improved from 0.68584 to 0.68529, saving model to best_cnn_2d_vnemos.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m3113/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5ms/step - accuracy: 0.9793 - loss: 0.6933 - val_accuracy: 0.9662 - val_loss: 0.6853 - learning_rate: 2.0000e-05\n",
            "Epoch 110/200\n",
            "\u001b[1m3108/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9804 - loss: 0.6892\n",
            "Epoch 110: val_loss improved from 0.68529 to 0.68004, saving model to best_cnn_2d_vnemos.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m3113/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - accuracy: 0.9804 - loss: 0.6892 - val_accuracy: 0.9682 - val_loss: 0.6800 - learning_rate: 2.0000e-05\n",
            "Epoch 111/200\n",
            "\u001b[1m3103/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9794 - loss: 0.6870\n",
            "Epoch 111: val_loss did not improve from 0.68004\n",
            "\u001b[1m3113/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - accuracy: 0.9794 - loss: 0.6870 - val_accuracy: 0.9655 - val_loss: 0.6824 - learning_rate: 2.0000e-05\n",
            "Epoch 112/200\n",
            "\u001b[1m3105/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9797 - loss: 0.6836\n",
            "Epoch 112: val_loss improved from 0.68004 to 0.67755, saving model to best_cnn_2d_vnemos.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m3113/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5ms/step - accuracy: 0.9797 - loss: 0.6836 - val_accuracy: 0.9663 - val_loss: 0.6775 - learning_rate: 2.0000e-05\n",
            "Epoch 113/200\n",
            "\u001b[1m3107/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9803 - loss: 0.6808\n",
            "Epoch 113: val_loss improved from 0.67755 to 0.67641, saving model to best_cnn_2d_vnemos.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m3113/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5ms/step - accuracy: 0.9803 - loss: 0.6808 - val_accuracy: 0.9651 - val_loss: 0.6764 - learning_rate: 2.0000e-05\n",
            "Epoch 114/200\n",
            "\u001b[1m3111/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9811 - loss: 0.6778\n",
            "Epoch 114: val_loss improved from 0.67641 to 0.67204, saving model to best_cnn_2d_vnemos.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m3113/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5ms/step - accuracy: 0.9811 - loss: 0.6778 - val_accuracy: 0.9655 - val_loss: 0.6720 - learning_rate: 2.0000e-05\n",
            "Epoch 115/200\n",
            "\u001b[1m3106/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9823 - loss: 0.6735\n",
            "Epoch 115: val_loss improved from 0.67204 to 0.66774, saving model to best_cnn_2d_vnemos.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m3113/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - accuracy: 0.9823 - loss: 0.6735 - val_accuracy: 0.9661 - val_loss: 0.6677 - learning_rate: 2.0000e-05\n",
            "Epoch 116/200\n",
            "\u001b[1m3106/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9803 - loss: 0.6737\n",
            "Epoch 116: val_loss did not improve from 0.66774\n",
            "\u001b[1m3113/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - accuracy: 0.9803 - loss: 0.6737 - val_accuracy: 0.9660 - val_loss: 0.6679 - learning_rate: 2.0000e-05\n",
            "Epoch 117/200\n",
            "\u001b[1m3108/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9828 - loss: 0.6696\n",
            "Epoch 117: val_loss improved from 0.66774 to 0.66408, saving model to best_cnn_2d_vnemos.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m3113/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5ms/step - accuracy: 0.9828 - loss: 0.6696 - val_accuracy: 0.9666 - val_loss: 0.6641 - learning_rate: 2.0000e-05\n",
            "Epoch 118/200\n",
            "\u001b[1m3104/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9822 - loss: 0.6662\n",
            "Epoch 118: val_loss did not improve from 0.66408\n",
            "\u001b[1m3113/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - accuracy: 0.9822 - loss: 0.6663 - val_accuracy: 0.9659 - val_loss: 0.6679 - learning_rate: 2.0000e-05\n",
            "Epoch 119/200\n",
            "\u001b[1m3106/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9830 - loss: 0.6633\n",
            "Epoch 119: val_loss improved from 0.66408 to 0.66318, saving model to best_cnn_2d_vnemos.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m3113/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5ms/step - accuracy: 0.9830 - loss: 0.6633 - val_accuracy: 0.9669 - val_loss: 0.6632 - learning_rate: 2.0000e-05\n",
            "Epoch 120/200\n",
            "\u001b[1m3112/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9818 - loss: 0.6618\n",
            "Epoch 120: val_loss improved from 0.66318 to 0.66012, saving model to best_cnn_2d_vnemos.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m3113/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - accuracy: 0.9818 - loss: 0.6618 - val_accuracy: 0.9667 - val_loss: 0.6601 - learning_rate: 2.0000e-05\n",
            "Epoch 121/200\n",
            "\u001b[1m3101/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9815 - loss: 0.6614\n",
            "Epoch 121: val_loss did not improve from 0.66012\n",
            "\u001b[1m3113/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - accuracy: 0.9815 - loss: 0.6614 - val_accuracy: 0.9642 - val_loss: 0.6613 - learning_rate: 2.0000e-05\n",
            "Epoch 122/200\n",
            "\u001b[1m3104/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9833 - loss: 0.6593\n",
            "Epoch 122: val_loss improved from 0.66012 to 0.65833, saving model to best_cnn_2d_vnemos.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m3113/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - accuracy: 0.9833 - loss: 0.6593 - val_accuracy: 0.9669 - val_loss: 0.6583 - learning_rate: 2.0000e-05\n",
            "Epoch 123/200\n",
            "\u001b[1m3112/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9834 - loss: 0.6567\n",
            "Epoch 123: val_loss improved from 0.65833 to 0.65285, saving model to best_cnn_2d_vnemos.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m3113/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - accuracy: 0.9834 - loss: 0.6567 - val_accuracy: 0.9685 - val_loss: 0.6528 - learning_rate: 2.0000e-05\n",
            "Epoch 124/200\n",
            "\u001b[1m3100/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9825 - loss: 0.6559\n",
            "Epoch 124: val_loss did not improve from 0.65285\n",
            "\u001b[1m3113/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - accuracy: 0.9825 - loss: 0.6559 - val_accuracy: 0.9674 - val_loss: 0.6543 - learning_rate: 2.0000e-05\n",
            "Epoch 125/200\n",
            "\u001b[1m3110/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9830 - loss: 0.6542\n",
            "Epoch 125: val_loss improved from 0.65285 to 0.64939, saving model to best_cnn_2d_vnemos.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m3113/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5ms/step - accuracy: 0.9830 - loss: 0.6542 - val_accuracy: 0.9692 - val_loss: 0.6494 - learning_rate: 2.0000e-05\n",
            "Epoch 126/200\n",
            "\u001b[1m3102/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9831 - loss: 0.6513\n",
            "Epoch 126: val_loss did not improve from 0.64939\n",
            "\u001b[1m3113/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5ms/step - accuracy: 0.9831 - loss: 0.6513 - val_accuracy: 0.9663 - val_loss: 0.6548 - learning_rate: 2.0000e-05\n",
            "Epoch 127/200\n",
            "\u001b[1m3105/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9840 - loss: 0.6497\n",
            "Epoch 127: val_loss did not improve from 0.64939\n",
            "\u001b[1m3113/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5ms/step - accuracy: 0.9840 - loss: 0.6497 - val_accuracy: 0.9679 - val_loss: 0.6526 - learning_rate: 2.0000e-05\n",
            "Epoch 128/200\n",
            "\u001b[1m3106/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9832 - loss: 0.6500\n",
            "Epoch 128: val_loss improved from 0.64939 to 0.64851, saving model to best_cnn_2d_vnemos.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m3113/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - accuracy: 0.9832 - loss: 0.6500 - val_accuracy: 0.9670 - val_loss: 0.6485 - learning_rate: 2.0000e-05\n",
            "Epoch 129/200\n",
            "\u001b[1m3112/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9844 - loss: 0.6466\n",
            "Epoch 129: val_loss did not improve from 0.64851\n",
            "\u001b[1m3113/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - accuracy: 0.9844 - loss: 0.6466 - val_accuracy: 0.9660 - val_loss: 0.6501 - learning_rate: 2.0000e-05\n",
            "Epoch 130/200\n",
            "\u001b[1m3110/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9826 - loss: 0.6491\n",
            "Epoch 130: val_loss improved from 0.64851 to 0.64576, saving model to best_cnn_2d_vnemos.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m3113/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - accuracy: 0.9826 - loss: 0.6491 - val_accuracy: 0.9682 - val_loss: 0.6458 - learning_rate: 2.0000e-05\n",
            "Epoch 131/200\n",
            "\u001b[1m3104/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9842 - loss: 0.6457\n",
            "Epoch 131: val_loss did not improve from 0.64576\n",
            "\u001b[1m3113/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - accuracy: 0.9842 - loss: 0.6457 - val_accuracy: 0.9670 - val_loss: 0.6478 - learning_rate: 2.0000e-05\n",
            "Epoch 132/200\n",
            "\u001b[1m3109/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9822 - loss: 0.6457\n",
            "Epoch 132: val_loss did not improve from 0.64576\n",
            "\u001b[1m3113/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - accuracy: 0.9822 - loss: 0.6457 - val_accuracy: 0.9670 - val_loss: 0.6492 - learning_rate: 2.0000e-05\n",
            "Epoch 133/200\n",
            "\u001b[1m3111/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9840 - loss: 0.6434\n",
            "Epoch 133: val_loss did not improve from 0.64576\n",
            "\u001b[1m3113/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - accuracy: 0.9840 - loss: 0.6434 - val_accuracy: 0.9638 - val_loss: 0.6484 - learning_rate: 2.0000e-05\n",
            "Epoch 134/200\n",
            "\u001b[1m3104/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9829 - loss: 0.6436\n",
            "Epoch 134: val_loss did not improve from 0.64576\n",
            "\u001b[1m3113/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - accuracy: 0.9829 - loss: 0.6436 - val_accuracy: 0.9656 - val_loss: 0.6471 - learning_rate: 2.0000e-05\n",
            "Epoch 135/200\n",
            "\u001b[1m3107/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9837 - loss: 0.6418\n",
            "Epoch 135: val_loss did not improve from 0.64576\n",
            "\u001b[1m3113/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - accuracy: 0.9837 - loss: 0.6418 - val_accuracy: 0.9646 - val_loss: 0.6466 - learning_rate: 2.0000e-05\n",
            "Epoch 136/200\n",
            "\u001b[1m3112/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9841 - loss: 0.6410\n",
            "Epoch 136: val_loss improved from 0.64576 to 0.64190, saving model to best_cnn_2d_vnemos.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m3113/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5ms/step - accuracy: 0.9841 - loss: 0.6410 - val_accuracy: 0.9689 - val_loss: 0.6419 - learning_rate: 2.0000e-05\n",
            "Epoch 137/200\n",
            "\u001b[1m3104/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9843 - loss: 0.6380\n",
            "Epoch 137: val_loss did not improve from 0.64190\n",
            "\u001b[1m3113/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - accuracy: 0.9842 - loss: 0.6380 - val_accuracy: 0.9665 - val_loss: 0.6444 - learning_rate: 2.0000e-05\n",
            "Epoch 138/200\n",
            "\u001b[1m3104/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9846 - loss: 0.6388\n",
            "Epoch 138: val_loss did not improve from 0.64190\n",
            "\u001b[1m3113/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - accuracy: 0.9846 - loss: 0.6388 - val_accuracy: 0.9659 - val_loss: 0.6426 - learning_rate: 2.0000e-05\n",
            "Epoch 139/200\n",
            "\u001b[1m3106/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9840 - loss: 0.6375\n",
            "Epoch 139: val_loss improved from 0.64190 to 0.64077, saving model to best_cnn_2d_vnemos.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m3113/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5ms/step - accuracy: 0.9840 - loss: 0.6375 - val_accuracy: 0.9677 - val_loss: 0.6408 - learning_rate: 2.0000e-05\n",
            "Epoch 140/200\n",
            "\u001b[1m3112/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9852 - loss: 0.6354\n",
            "Epoch 140: val_loss improved from 0.64077 to 0.63788, saving model to best_cnn_2d_vnemos.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m3113/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5ms/step - accuracy: 0.9852 - loss: 0.6354 - val_accuracy: 0.9680 - val_loss: 0.6379 - learning_rate: 2.0000e-05\n",
            "Epoch 141/200\n",
            "\u001b[1m3112/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9843 - loss: 0.6358\n",
            "Epoch 141: val_loss did not improve from 0.63788\n",
            "\u001b[1m3113/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - accuracy: 0.9843 - loss: 0.6358 - val_accuracy: 0.9636 - val_loss: 0.6406 - learning_rate: 2.0000e-05\n",
            "Epoch 142/200\n",
            "\u001b[1m3108/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9835 - loss: 0.6366\n",
            "Epoch 142: val_loss did not improve from 0.63788\n",
            "\u001b[1m3113/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 5ms/step - accuracy: 0.9835 - loss: 0.6366 - val_accuracy: 0.9669 - val_loss: 0.6388 - learning_rate: 2.0000e-05\n",
            "Epoch 143/200\n",
            "\u001b[1m3109/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9837 - loss: 0.6364\n",
            "Epoch 143: val_loss did not improve from 0.63788\n",
            "\u001b[1m3113/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5ms/step - accuracy: 0.9837 - loss: 0.6364 - val_accuracy: 0.9661 - val_loss: 0.6391 - learning_rate: 2.0000e-05\n",
            "Epoch 144/200\n",
            "\u001b[1m3113/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9846 - loss: 0.6340\n",
            "Epoch 144: val_loss did not improve from 0.63788\n",
            "\u001b[1m3113/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - accuracy: 0.9846 - loss: 0.6340 - val_accuracy: 0.9650 - val_loss: 0.6406 - learning_rate: 2.0000e-05\n",
            "Epoch 145/200\n",
            "\u001b[1m3109/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9839 - loss: 0.6336\n",
            "Epoch 145: val_loss improved from 0.63788 to 0.63496, saving model to best_cnn_2d_vnemos.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m3113/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5ms/step - accuracy: 0.9839 - loss: 0.6336 - val_accuracy: 0.9682 - val_loss: 0.6350 - learning_rate: 2.0000e-05\n",
            "Epoch 146/200\n",
            "\u001b[1m3105/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9861 - loss: 0.6311\n",
            "Epoch 146: val_loss improved from 0.63496 to 0.63398, saving model to best_cnn_2d_vnemos.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m3113/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5ms/step - accuracy: 0.9861 - loss: 0.6311 - val_accuracy: 0.9683 - val_loss: 0.6340 - learning_rate: 2.0000e-05\n",
            "Epoch 147/200\n",
            "\u001b[1m3101/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9835 - loss: 0.6342\n",
            "Epoch 147: val_loss did not improve from 0.63398\n",
            "\u001b[1m3113/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - accuracy: 0.9835 - loss: 0.6342 - val_accuracy: 0.9672 - val_loss: 0.6362 - learning_rate: 2.0000e-05\n",
            "Epoch 148/200\n",
            "\u001b[1m3112/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9843 - loss: 0.6311\n",
            "Epoch 148: val_loss improved from 0.63398 to 0.63364, saving model to best_cnn_2d_vnemos.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m3113/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5ms/step - accuracy: 0.9843 - loss: 0.6311 - val_accuracy: 0.9680 - val_loss: 0.6336 - learning_rate: 2.0000e-05\n",
            "Epoch 149/200\n",
            "\u001b[1m3104/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9844 - loss: 0.6299\n",
            "Epoch 149: val_loss did not improve from 0.63364\n",
            "\u001b[1m3113/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - accuracy: 0.9844 - loss: 0.6299 - val_accuracy: 0.9677 - val_loss: 0.6341 - learning_rate: 2.0000e-05\n",
            "Epoch 150/200\n",
            "\u001b[1m3110/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9844 - loss: 0.6299\n",
            "Epoch 150: val_loss did not improve from 0.63364\n",
            "\u001b[1m3113/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5ms/step - accuracy: 0.9844 - loss: 0.6299 - val_accuracy: 0.9651 - val_loss: 0.6356 - learning_rate: 2.0000e-05\n",
            "Epoch 151/200\n",
            "\u001b[1m3104/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9847 - loss: 0.6307\n",
            "Epoch 151: val_loss did not improve from 0.63364\n",
            "\u001b[1m3113/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5ms/step - accuracy: 0.9847 - loss: 0.6307 - val_accuracy: 0.9656 - val_loss: 0.6354 - learning_rate: 2.0000e-05\n",
            "Epoch 152/200\n",
            "\u001b[1m3109/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9844 - loss: 0.6307\n",
            "Epoch 152: val_loss did not improve from 0.63364\n",
            "\u001b[1m3113/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - accuracy: 0.9844 - loss: 0.6307 - val_accuracy: 0.9644 - val_loss: 0.6338 - learning_rate: 2.0000e-05\n",
            "Epoch 153/200\n",
            "\u001b[1m3100/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9853 - loss: 0.6272\n",
            "Epoch 153: val_loss did not improve from 0.63364\n",
            "\u001b[1m3113/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - accuracy: 0.9853 - loss: 0.6272 - val_accuracy: 0.9669 - val_loss: 0.6343 - learning_rate: 2.0000e-05\n",
            "Epoch 154/200\n",
            "\u001b[1m3112/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9847 - loss: 0.6291\n",
            "Epoch 154: val_loss did not improve from 0.63364\n",
            "\u001b[1m3113/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - accuracy: 0.9847 - loss: 0.6291 - val_accuracy: 0.9654 - val_loss: 0.6346 - learning_rate: 2.0000e-05\n",
            "Epoch 155/200\n",
            "\u001b[1m3106/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9838 - loss: 0.6288\n",
            "Epoch 155: val_loss did not improve from 0.63364\n",
            "\u001b[1m3113/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - accuracy: 0.9838 - loss: 0.6289 - val_accuracy: 0.9649 - val_loss: 0.6350 - learning_rate: 2.0000e-05\n",
            "Epoch 156/200\n",
            "\u001b[1m3109/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9837 - loss: 0.6294\n",
            "Epoch 156: val_loss improved from 0.63364 to 0.63100, saving model to best_cnn_2d_vnemos.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m3113/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5ms/step - accuracy: 0.9837 - loss: 0.6294 - val_accuracy: 0.9676 - val_loss: 0.6310 - learning_rate: 2.0000e-05\n",
            "Epoch 157/200\n",
            "\u001b[1m3111/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9845 - loss: 0.6279\n",
            "Epoch 157: val_loss did not improve from 0.63100\n",
            "\u001b[1m3113/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - accuracy: 0.9845 - loss: 0.6279 - val_accuracy: 0.9672 - val_loss: 0.6318 - learning_rate: 2.0000e-05\n",
            "Epoch 158/200\n",
            "\u001b[1m3100/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9853 - loss: 0.6265\n",
            "Epoch 158: val_loss improved from 0.63100 to 0.63094, saving model to best_cnn_2d_vnemos.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m3113/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - accuracy: 0.9853 - loss: 0.6265 - val_accuracy: 0.9677 - val_loss: 0.6309 - learning_rate: 2.0000e-05\n",
            "Epoch 159/200\n",
            "\u001b[1m3109/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9844 - loss: 0.6271\n",
            "Epoch 159: val_loss improved from 0.63094 to 0.62814, saving model to best_cnn_2d_vnemos.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m3113/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5ms/step - accuracy: 0.9844 - loss: 0.6271 - val_accuracy: 0.9684 - val_loss: 0.6281 - learning_rate: 2.0000e-05\n",
            "Epoch 160/200\n",
            "\u001b[1m3112/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9862 - loss: 0.6258\n",
            "Epoch 160: val_loss did not improve from 0.62814\n",
            "\u001b[1m3113/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - accuracy: 0.9862 - loss: 0.6258 - val_accuracy: 0.9649 - val_loss: 0.6336 - learning_rate: 2.0000e-05\n",
            "Epoch 161/200\n",
            "\u001b[1m3102/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9848 - loss: 0.6263\n",
            "Epoch 161: val_loss did not improve from 0.62814\n",
            "\u001b[1m3113/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - accuracy: 0.9848 - loss: 0.6263 - val_accuracy: 0.9672 - val_loss: 0.6294 - learning_rate: 2.0000e-05\n",
            "Epoch 162/200\n",
            "\u001b[1m3111/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9850 - loss: 0.6244\n",
            "Epoch 162: val_loss did not improve from 0.62814\n",
            "\u001b[1m3113/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - accuracy: 0.9850 - loss: 0.6244 - val_accuracy: 0.9653 - val_loss: 0.6308 - learning_rate: 2.0000e-05\n",
            "Epoch 163/200\n",
            "\u001b[1m3108/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9859 - loss: 0.6232\n",
            "Epoch 163: val_loss did not improve from 0.62814\n",
            "\u001b[1m3113/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - accuracy: 0.9859 - loss: 0.6232 - val_accuracy: 0.9642 - val_loss: 0.6329 - learning_rate: 2.0000e-05\n",
            "Epoch 164/200\n",
            "\u001b[1m3104/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9852 - loss: 0.6235\n",
            "Epoch 164: val_loss did not improve from 0.62814\n",
            "\u001b[1m3113/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - accuracy: 0.9852 - loss: 0.6235 - val_accuracy: 0.9650 - val_loss: 0.6335 - learning_rate: 2.0000e-05\n",
            "Epoch 165/200\n",
            "\u001b[1m3109/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9853 - loss: 0.6232\n",
            "Epoch 165: val_loss improved from 0.62814 to 0.62761, saving model to best_cnn_2d_vnemos.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m3113/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5ms/step - accuracy: 0.9852 - loss: 0.6232 - val_accuracy: 0.9663 - val_loss: 0.6276 - learning_rate: 2.0000e-05\n",
            "Epoch 166/200\n",
            "\u001b[1m3107/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9846 - loss: 0.6233\n",
            "Epoch 166: val_loss did not improve from 0.62761\n",
            "\u001b[1m3113/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - accuracy: 0.9846 - loss: 0.6233 - val_accuracy: 0.9665 - val_loss: 0.6293 - learning_rate: 2.0000e-05\n",
            "Epoch 167/200\n",
            "\u001b[1m3105/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9857 - loss: 0.6228\n",
            "Epoch 167: val_loss did not improve from 0.62761\n",
            "\u001b[1m3113/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 5ms/step - accuracy: 0.9857 - loss: 0.6228 - val_accuracy: 0.9640 - val_loss: 0.6314 - learning_rate: 2.0000e-05\n",
            "Epoch 168/200\n",
            "\u001b[1m3107/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9856 - loss: 0.6223\n",
            "Epoch 168: val_loss did not improve from 0.62761\n",
            "\u001b[1m3113/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 5ms/step - accuracy: 0.9856 - loss: 0.6223 - val_accuracy: 0.9656 - val_loss: 0.6293 - learning_rate: 2.0000e-05\n",
            "Epoch 169/200\n",
            "\u001b[1m3104/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9855 - loss: 0.6220\n",
            "Epoch 169: val_loss did not improve from 0.62761\n",
            "\u001b[1m3113/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 5ms/step - accuracy: 0.9855 - loss: 0.6220 - val_accuracy: 0.9642 - val_loss: 0.6342 - learning_rate: 2.0000e-05\n",
            "Epoch 170/200\n",
            "\u001b[1m3107/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9863 - loss: 0.6211\n",
            "Epoch 170: val_loss did not improve from 0.62761\n",
            "\u001b[1m3113/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 5ms/step - accuracy: 0.9863 - loss: 0.6211 - val_accuracy: 0.9641 - val_loss: 0.6345 - learning_rate: 2.0000e-05\n",
            "Epoch 171/200\n",
            "\u001b[1m3108/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9851 - loss: 0.6221\n",
            "Epoch 171: val_loss improved from 0.62761 to 0.62489, saving model to best_cnn_2d_vnemos.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m3113/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 5ms/step - accuracy: 0.9851 - loss: 0.6221 - val_accuracy: 0.9665 - val_loss: 0.6249 - learning_rate: 2.0000e-05\n",
            "Epoch 172/200\n",
            "\u001b[1m3110/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9859 - loss: 0.6204\n",
            "Epoch 172: val_loss did not improve from 0.62489\n",
            "\u001b[1m3113/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 5ms/step - accuracy: 0.9859 - loss: 0.6204 - val_accuracy: 0.9636 - val_loss: 0.6319 - learning_rate: 2.0000e-05\n",
            "Epoch 173/200\n",
            "\u001b[1m3103/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9869 - loss: 0.6200\n",
            "Epoch 173: val_loss did not improve from 0.62489\n",
            "\u001b[1m3113/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 5ms/step - accuracy: 0.9869 - loss: 0.6200 - val_accuracy: 0.9676 - val_loss: 0.6259 - learning_rate: 2.0000e-05\n",
            "Epoch 174/200\n",
            "\u001b[1m3106/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9837 - loss: 0.6228\n",
            "Epoch 174: val_loss did not improve from 0.62489\n",
            "\u001b[1m3113/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 5ms/step - accuracy: 0.9837 - loss: 0.6228 - val_accuracy: 0.9636 - val_loss: 0.6307 - learning_rate: 2.0000e-05\n",
            "Epoch 175/200\n",
            "\u001b[1m3112/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9867 - loss: 0.6202\n",
            "Epoch 175: val_loss did not improve from 0.62489\n",
            "\u001b[1m3113/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 5ms/step - accuracy: 0.9867 - loss: 0.6202 - val_accuracy: 0.9624 - val_loss: 0.6294 - learning_rate: 2.0000e-05\n",
            "Epoch 176/200\n",
            "\u001b[1m3109/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9850 - loss: 0.6204\n",
            "Epoch 176: val_loss improved from 0.62489 to 0.62480, saving model to best_cnn_2d_vnemos.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m3113/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 5ms/step - accuracy: 0.9850 - loss: 0.6204 - val_accuracy: 0.9669 - val_loss: 0.6248 - learning_rate: 2.0000e-05\n",
            "Epoch 177/200\n",
            "\u001b[1m3106/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9850 - loss: 0.6212\n",
            "Epoch 177: val_loss did not improve from 0.62480\n",
            "\u001b[1m3113/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 5ms/step - accuracy: 0.9850 - loss: 0.6212 - val_accuracy: 0.9632 - val_loss: 0.6292 - learning_rate: 2.0000e-05\n",
            "Epoch 178/200\n",
            "\u001b[1m3110/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9847 - loss: 0.6202\n",
            "Epoch 178: val_loss improved from 0.62480 to 0.62301, saving model to best_cnn_2d_vnemos.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m3113/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 5ms/step - accuracy: 0.9847 - loss: 0.6202 - val_accuracy: 0.9666 - val_loss: 0.6230 - learning_rate: 2.0000e-05\n",
            "Epoch 179/200\n",
            "\u001b[1m3112/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9860 - loss: 0.6198\n",
            "Epoch 179: val_loss did not improve from 0.62301\n",
            "\u001b[1m3113/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 5ms/step - accuracy: 0.9860 - loss: 0.6198 - val_accuracy: 0.9630 - val_loss: 0.6296 - learning_rate: 2.0000e-05\n",
            "Epoch 180/200\n",
            "\u001b[1m3113/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9842 - loss: 0.6212\n",
            "Epoch 180: val_loss did not improve from 0.62301\n",
            "\u001b[1m3113/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 5ms/step - accuracy: 0.9842 - loss: 0.6212 - val_accuracy: 0.9663 - val_loss: 0.6270 - learning_rate: 2.0000e-05\n",
            "Epoch 181/200\n",
            "\u001b[1m3111/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9857 - loss: 0.6193\n",
            "Epoch 181: val_loss did not improve from 0.62301\n",
            "\u001b[1m3113/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 5ms/step - accuracy: 0.9857 - loss: 0.6193 - val_accuracy: 0.9634 - val_loss: 0.6298 - learning_rate: 2.0000e-05\n",
            "Epoch 182/200\n",
            "\u001b[1m3111/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9867 - loss: 0.6192\n",
            "Epoch 182: val_loss did not improve from 0.62301\n",
            "\u001b[1m3113/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 5ms/step - accuracy: 0.9867 - loss: 0.6192 - val_accuracy: 0.9639 - val_loss: 0.6298 - learning_rate: 2.0000e-05\n",
            "Epoch 183/200\n",
            "\u001b[1m3106/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9849 - loss: 0.6197\n",
            "Epoch 183: val_loss did not improve from 0.62301\n",
            "\u001b[1m3113/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 5ms/step - accuracy: 0.9849 - loss: 0.6197 - val_accuracy: 0.9648 - val_loss: 0.6243 - learning_rate: 2.0000e-05\n",
            "Epoch 184/200\n",
            "\u001b[1m3105/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9854 - loss: 0.6188\n",
            "Epoch 184: val_loss did not improve from 0.62301\n",
            "\u001b[1m3113/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 5ms/step - accuracy: 0.9854 - loss: 0.6188 - val_accuracy: 0.9632 - val_loss: 0.6308 - learning_rate: 2.0000e-05\n",
            "Epoch 185/200\n",
            "\u001b[1m3107/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9849 - loss: 0.6175\n",
            "Epoch 185: val_loss did not improve from 0.62301\n",
            "\u001b[1m3113/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 5ms/step - accuracy: 0.9849 - loss: 0.6175 - val_accuracy: 0.9639 - val_loss: 0.6276 - learning_rate: 2.0000e-05\n",
            "Epoch 186/200\n",
            "\u001b[1m3107/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9855 - loss: 0.6177\n",
            "Epoch 186: val_loss did not improve from 0.62301\n",
            "\u001b[1m3113/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 5ms/step - accuracy: 0.9855 - loss: 0.6177 - val_accuracy: 0.9635 - val_loss: 0.6294 - learning_rate: 2.0000e-05\n",
            "Epoch 187/200\n",
            "\u001b[1m3104/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9869 - loss: 0.6171\n",
            "Epoch 187: val_loss did not improve from 0.62301\n",
            "\u001b[1m3113/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - accuracy: 0.9869 - loss: 0.6171 - val_accuracy: 0.9667 - val_loss: 0.6231 - learning_rate: 2.0000e-05\n",
            "Epoch 188/200\n",
            "\u001b[1m3101/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9865 - loss: 0.6187\n",
            "Epoch 188: val_loss improved from 0.62301 to 0.62243, saving model to best_cnn_2d_vnemos.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m3113/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 5ms/step - accuracy: 0.9865 - loss: 0.6187 - val_accuracy: 0.9672 - val_loss: 0.6224 - learning_rate: 2.0000e-05\n",
            "Epoch 189/200\n",
            "\u001b[1m3103/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9868 - loss: 0.6164\n",
            "Epoch 189: val_loss did not improve from 0.62243\n",
            "\u001b[1m3113/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 5ms/step - accuracy: 0.9868 - loss: 0.6164 - val_accuracy: 0.9668 - val_loss: 0.6245 - learning_rate: 2.0000e-05\n",
            "Epoch 190/200\n",
            "\u001b[1m3106/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9850 - loss: 0.6184\n",
            "Epoch 190: val_loss did not improve from 0.62243\n",
            "\u001b[1m3113/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 5ms/step - accuracy: 0.9850 - loss: 0.6184 - val_accuracy: 0.9671 - val_loss: 0.6246 - learning_rate: 2.0000e-05\n",
            "Epoch 191/200\n",
            "\u001b[1m3102/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9860 - loss: 0.6171\n",
            "Epoch 191: val_loss did not improve from 0.62243\n",
            "\u001b[1m3113/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 5ms/step - accuracy: 0.9860 - loss: 0.6171 - val_accuracy: 0.9619 - val_loss: 0.6292 - learning_rate: 2.0000e-05\n",
            "Epoch 192/200\n",
            "\u001b[1m3103/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9854 - loss: 0.6170\n",
            "Epoch 192: val_loss did not improve from 0.62243\n",
            "\u001b[1m3113/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 5ms/step - accuracy: 0.9854 - loss: 0.6171 - val_accuracy: 0.9665 - val_loss: 0.6238 - learning_rate: 2.0000e-05\n",
            "Epoch 193/200\n",
            "\u001b[1m3110/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9861 - loss: 0.6172\n",
            "Epoch 193: val_loss did not improve from 0.62243\n",
            "\u001b[1m3113/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 5ms/step - accuracy: 0.9861 - loss: 0.6172 - val_accuracy: 0.9671 - val_loss: 0.6226 - learning_rate: 2.0000e-05\n",
            "Epoch 194/200\n",
            "\u001b[1m3112/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9856 - loss: 0.6155\n",
            "Epoch 194: val_loss improved from 0.62243 to 0.62187, saving model to best_cnn_2d_vnemos.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m3113/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 5ms/step - accuracy: 0.9856 - loss: 0.6155 - val_accuracy: 0.9675 - val_loss: 0.6219 - learning_rate: 2.0000e-05\n",
            "Epoch 195/200\n",
            "\u001b[1m3108/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9861 - loss: 0.6147\n",
            "Epoch 195: val_loss did not improve from 0.62187\n",
            "\u001b[1m3113/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 5ms/step - accuracy: 0.9861 - loss: 0.6148 - val_accuracy: 0.9644 - val_loss: 0.6271 - learning_rate: 2.0000e-05\n",
            "Epoch 196/200\n",
            "\u001b[1m3103/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9856 - loss: 0.6164\n",
            "Epoch 196: val_loss improved from 0.62187 to 0.62134, saving model to best_cnn_2d_vnemos.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m3113/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 5ms/step - accuracy: 0.9856 - loss: 0.6164 - val_accuracy: 0.9667 - val_loss: 0.6213 - learning_rate: 2.0000e-05\n",
            "Epoch 197/200\n",
            "\u001b[1m3109/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9848 - loss: 0.6166\n",
            "Epoch 197: val_loss did not improve from 0.62134\n",
            "\u001b[1m3113/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 5ms/step - accuracy: 0.9848 - loss: 0.6166 - val_accuracy: 0.9652 - val_loss: 0.6251 - learning_rate: 2.0000e-05\n",
            "Epoch 198/200\n",
            "\u001b[1m3112/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9846 - loss: 0.6177\n",
            "Epoch 198: val_loss did not improve from 0.62134\n",
            "\u001b[1m3113/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 5ms/step - accuracy: 0.9846 - loss: 0.6177 - val_accuracy: 0.9662 - val_loss: 0.6214 - learning_rate: 2.0000e-05\n",
            "Epoch 199/200\n",
            "\u001b[1m3110/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9859 - loss: 0.6154\n",
            "Epoch 199: val_loss improved from 0.62134 to 0.62043, saving model to best_cnn_2d_vnemos.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m3113/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 5ms/step - accuracy: 0.9859 - loss: 0.6154 - val_accuracy: 0.9667 - val_loss: 0.6204 - learning_rate: 2.0000e-05\n",
            "Epoch 200/200\n",
            "\u001b[1m3103/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9856 - loss: 0.6152\n",
            "Epoch 200: val_loss did not improve from 0.62043\n",
            "\u001b[1m3113/3113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 5ms/step - accuracy: 0.9856 - loss: 0.6152 - val_accuracy: 0.9650 - val_loss: 0.6243 - learning_rate: 2.0000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Đánh giá trên tập kiểm tra:\n",
            " - Loss: 0.6204\n",
            " - Accuracy: 0.9667\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "    best_model = tf.keras.models.load_model('best_cnn_2d_vnemos.h5')\n",
        "    root_folder_test = \"/content/emotion_test/Emotions-test\"\n",
        "    folders_test = [f for f in glob.glob(os.path.join(root_folder_test, \"*\")) if os.path.isdir(f)]\n",
        "    all_files_test = []\n",
        "    for folder in folders_test:\n",
        "        all_files_test.extend(glob.glob(os.path.join(folder, \"**\", \"*.wav\"), recursive=True))\n",
        "    for test_path in all_files_test:\n",
        "        predicted_emotion = predict_emotion(test_path, best_model)\n",
        "        print(f\"Dự đoán cảm xúc {os.path.basename(test_path)} (best model): {predicted_emotion}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bb5SII2o9MH-",
        "outputId": "ebf9fd65-48a1-4e12-8811-6e8bd636c202"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dự đoán cảm xúc YAF_witch_happy.wav (best model): Happy\n",
            "Dự đoán cảm xúc YAF_tell_happy.wav (best model): Happy\n",
            "Dự đoán cảm xúc a06.wav (best model): Happy\n",
            "Dự đoán cảm xúc a01.wav (best model): Happy\n",
            "Dự đoán cảm xúc a05.wav (best model): Happy\n",
            "Dự đoán cảm xúc YAF_wife_happy.wav (best model): Happy\n",
            "Dự đoán cảm xúc YAF_turn_happy.wav (best model): Happy\n",
            "Dự đoán cảm xúc YAF_wheat_happy.wav (best model): Happy\n",
            "Dự đoán cảm xúc d01.wav (best model): Happy\n",
            "Dự đoán cảm xúc YAF_tough_happy.wav (best model): Happy\n",
            "Dự đoán cảm xúc a02.wav (best model): Happy\n",
            "Dự đoán cảm xúc YAF_talk_happy.wav (best model): Happy\n",
            "Dự đoán cảm xúc a15.wav (best model): Happy\n",
            "Dự đoán cảm xúc YAF_walk_happy.wav (best model): Happy\n",
            "Dự đoán cảm xúc YAF_thin_happy.wav (best model): Happy\n",
            "Dự đoán cảm xúc YAF_third_happy.wav (best model): Happy\n",
            "Dự đoán cảm xúc YAF_when_happy.wav (best model): Happy\n",
            "Dự đoán cảm xúc YAF_team_happy.wav (best model): Happy\n",
            "Dự đoán cảm xúc YAF_voice_happy.wav (best model): Happy\n",
            "Dự đoán cảm xúc YAF_such_happy.wav (best model): Happy\n",
            "Dự đoán cảm xúc d05.wav (best model): Happy\n",
            "Dự đoán cảm xúc a03.wav (best model): Happy\n",
            "Dự đoán cảm xúc a04.wav (best model): Happy\n",
            "Dự đoán cảm xúc YAF_wag_happy.wav (best model): Happy\n",
            "Dự đoán cảm xúc YAF_void_happy.wav (best model): Happy\n",
            "Dự đoán cảm xúc YAF_tire_happy.wav (best model): Happy\n",
            "Dự đoán cảm xúc YAF_sure_happy.wav (best model): Happy\n",
            "Dự đoán cảm xúc YAF_young_happy.wav (best model): Happy\n",
            "Dự đoán cảm xúc YAF_tip_happy.wav (best model): Happy\n",
            "Dự đoán cảm xúc YAF_time_happy.wav (best model): Happy\n",
            "Dự đoán cảm xúc YAF_thought_happy.wav (best model): Happy\n",
            "Dự đoán cảm xúc YAF_vote_happy.wav (best model): Happy\n",
            "Dự đoán cảm xúc d09.wav (best model): Happy\n",
            "Dự đoán cảm xúc a14.wav (best model): Happy\n",
            "Dự đoán cảm xúc d06.wav (best model): Happy\n",
            "Dự đoán cảm xúc d04.wav (best model): Happy\n",
            "Dự đoán cảm xúc YAF_yearn_happy.wav (best model): Happy\n",
            "Dự đoán cảm xúc a10.wav (best model): Happy\n",
            "Dự đoán cảm xúc YAF_thumb_happy.wav (best model): Happy\n",
            "Dự đoán cảm xúc a08.wav (best model): Happy\n",
            "Dự đoán cảm xúc d02.wav (best model): Happy\n",
            "Dự đoán cảm xúc YAF_whip_happy.wav (best model): Happy\n",
            "Dự đoán cảm xúc YAF_yes_happy.wav (best model): Happy\n",
            "Dự đoán cảm xúc YAF_ton_happy.wav (best model): Happy\n",
            "Dự đoán cảm xúc YAF_wire_happy.wav (best model): Happy\n",
            "Dự đoán cảm xúc YAF_vine_happy.wav (best model): Happy\n",
            "Dự đoán cảm xúc YAF_tape_happy.wav (best model): Happy\n",
            "Dự đoán cảm xúc d03.wav (best model): Happy\n",
            "Dự đoán cảm xúc d08.wav (best model): Happy\n",
            "Dự đoán cảm xúc a12.wav (best model): Happy\n",
            "Dự đoán cảm xúc YAF_tool_happy.wav (best model): Happy\n",
            "Dự đoán cảm xúc a11.wav (best model): Happy\n",
            "Dự đoán cảm xúc a07.wav (best model): Happy\n",
            "Dự đoán cảm xúc a13.wav (best model): Happy\n",
            "Dự đoán cảm xúc YAF_youth_happy.wav (best model): Happy\n",
            "Dự đoán cảm xúc d07.wav (best model): Happy\n",
            "Dự đoán cảm xúc YAF_wash_happy.wav (best model): Happy\n",
            "Dự đoán cảm xúc YAF_white_happy.wav (best model): Happy\n",
            "Dự đoán cảm xúc YAF_week_happy.wav (best model): Happy\n",
            "Dự đoán cảm xúc YAF_which_happy.wav (best model): Happy\n",
            "Dự đoán cảm xúc YAF_take_happy.wav (best model): Happy\n",
            "Dự đoán cảm xúc a09.wav (best model): Happy\n",
            "Dự đoán cảm xúc YAF_knock_angry.wav (best model): Angry\n",
            "Dự đoán cảm xúc YAF_loaf_angry.wav (best model): Angry\n",
            "Dự đoán cảm xúc YAF_kite_angry.wav (best model): Angry\n",
            "Dự đoán cảm xúc YAF_mill_angry.wav (best model): Angry\n",
            "Dự đoán cảm xúc n03.wav (best model): Angry\n",
            "Dự đoán cảm xúc YAF_lean_angry.wav (best model): Angry\n",
            "Dự đoán cảm xúc YAF_tough_angry.wav (best model): Angry\n",
            "Dự đoán cảm xúc YAF_lease_angry.wav (best model): Angry\n",
            "Dự đoán cảm xúc YAF_ton_angry.wav (best model): Angry\n",
            "Dự đoán cảm xúc YAF_met_angry.wav (best model): Angry\n",
            "Dự đoán cảm xúc n06.wav (best model): Angry\n",
            "Dự đoán cảm xúc YAF_king_angry.wav (best model): Angry\n",
            "Dự đoán cảm xúc YAF_tire_angry.wav (best model): Angry\n",
            "Dự đoán cảm xúc n08.wav (best model): Angry\n",
            "Dự đoán cảm xúc YAF_late_angry.wav (best model): Angry\n",
            "Dự đoán cảm xúc YAF_turn_angry.wav (best model): Angry\n",
            "Dự đoán cảm xúc YAF_love_angry.wav (best model): Angry\n",
            "Dự đoán cảm xúc YAF_make_angry.wav (best model): Angry\n",
            "Dự đoán cảm xúc n02.wav (best model): Angry\n",
            "Dự đoán cảm xúc YAF_lid_angry.wav (best model): Angry\n",
            "Dự đoán cảm xúc YAF_match_angry.wav (best model): Angry\n",
            "Dự đoán cảm xúc n09.wav (best model): Angry\n",
            "Dự đoán cảm xúc d05.wav (best model): Angry\n",
            "Dự đoán cảm xúc YAF_kick_angry.wav (best model): Angry\n",
            "Dự đoán cảm xúc YAF_life_angry.wav (best model): Angry\n",
            "Dự đoán cảm xúc d06.wav (best model): Angry\n",
            "Dự đoán cảm xúc d04.wav (best model): Angry\n",
            "Dự đoán cảm xúc YAF_lose_angry.wav (best model): Angry\n",
            "Dự đoán cảm xúc YAF_merge_angry.wav (best model): Angry\n",
            "Dự đoán cảm xúc YAF_long_angry.wav (best model): Angry\n",
            "Dự đoán cảm xúc YAF_tool_angry.wav (best model): Angry\n",
            "Dự đoán cảm xúc d02.wav (best model): Angry\n",
            "Dự đoán cảm xúc YAF_mood_angry.wav (best model): Angry\n",
            "Dự đoán cảm xúc YAF_mess_angry.wav (best model): Angry\n",
            "Dự đoán cảm xúc YAF_laud_angry.wav (best model): Angry\n",
            "Dự đoán cảm xúc YAF_live_angry.wav (best model): Angry\n",
            "Dự đoán cảm xúc YAF_moon_angry.wav (best model): Angry\n",
            "Dự đoán cảm xúc YAF_tip_angry.wav (best model): Angry\n",
            "Dự đoán cảm xúc n05.wav (best model): Angry\n",
            "Dự đoán cảm xúc n07.wav (best model): Angry\n",
            "Dự đoán cảm xúc d03.wav (best model): Angry\n",
            "Dự đoán cảm xúc YAF_lore_angry.wav (best model): Angry\n",
            "Dự đoán cảm xúc YAF_limb_angry.wav (best model): Angry\n",
            "Dự đoán cảm xúc d07.wav (best model): Angry\n",
            "Dự đoán cảm xúc YAF_kill_angry.wav (best model): Angry\n",
            "Dự đoán cảm xúc YAF_mode_angry.wav (best model): Angry\n",
            "Dự đoán cảm xúc YAF_lot_angry.wav (best model): Angry\n",
            "Dự đoán cảm xúc YAF_luck_angry.wav (best model): Angry\n",
            "Dự đoán cảm xúc n04.wav (best model): Angry\n",
            "Dự đoán cảm xúc YAF_mob_angry.wav (best model): Angry\n",
            "Dự đoán cảm xúc YAF_learn_angry.wav (best model): Angry\n",
            "Dự đoán cảm xúc YAF_witch_ps.wav (best model): Suprised\n",
            "Dự đoán cảm xúc YAF_tell_ps.wav (best model): Suprised\n",
            "Dự đoán cảm xúc YAF_tough_ps.wav (best model): Suprised\n",
            "Dự đoán cảm xúc YAF_wash_ps.wav (best model): Suprised\n",
            "Dự đoán cảm xúc YAF_ton_ps.wav (best model): Suprised\n",
            "Dự đoán cảm xúc YAF_vote_ps.wav (best model): Suprised\n",
            "Dự đoán cảm xúc YAF_wag_ps.wav (best model): Suprised\n",
            "Dự đoán cảm xúc YAF_thumb_ps.wav (best model): Suprised\n",
            "Dự đoán cảm xúc YAF_young_ps.wav (best model): Suprised\n",
            "Dự đoán cảm xúc YAF_turn_ps.wav (best model): Suprised\n",
            "Dự đoán cảm xúc YAF_team_ps.wav (best model): Suprised\n",
            "Dự đoán cảm xúc YAF_yearn_ps.wav (best model): Suprised\n",
            "Dự đoán cảm xúc YAF_tape_ps.wav (best model): Suprised\n",
            "Dự đoán cảm xúc YAF_wire_ps.wav (best model): Suprised\n",
            "Dự đoán cảm xúc YAF_which_ps.wav (best model): Suprised\n",
            "Dự đoán cảm xúc YAF_voice_ps.wav (best model): Suprised\n",
            "Dự đoán cảm xúc YAF_vine_ps.wav (best model): Suprised\n",
            "Dự đoán cảm xúc YAF_void_ps.wav (best model): Suprised\n",
            "Dự đoán cảm xúc YAF_wheat_ps.wav (best model): Suprised\n",
            "Dự đoán cảm xúc YAF_wife_ps.wav (best model): Suprised\n",
            "Dự đoán cảm xúc YAF_thought_ps.wav (best model): Suprised\n",
            "Dự đoán cảm xúc YAF_white_ps.wav (best model): Suprised\n",
            "Dự đoán cảm xúc YAF_third_ps.wav (best model): Suprised\n",
            "Dự đoán cảm xúc YAF_week_ps.wav (best model): Suprised\n",
            "Dự đoán cảm xúc YAF_tip_ps.wav (best model): Suprised\n",
            "Dự đoán cảm xúc YAF_talk_ps.wav (best model): Suprised\n",
            "Dự đoán cảm xúc YAF_whip_ps.wav (best model): Suprised\n",
            "Dự đoán cảm xúc YAF_when_ps.wav (best model): Suprised\n",
            "Dự đoán cảm xúc YAF_tool_ps.wav (best model): Suprised\n",
            "Dự đoán cảm xúc YAF_youth_ps.wav (best model): Suprised\n",
            "Dự đoán cảm xúc YAF_walk_ps.wav (best model): Suprised\n",
            "Dự đoán cảm xúc YAF_yes_ps.wav (best model): Suprised\n",
            "Dự đoán cảm xúc YAF_time_ps.wav (best model): Suprised\n",
            "Dự đoán cảm xúc YAF_tire_ps.wav (best model): Suprised\n",
            "Dự đoán cảm xúc YAF_thin_ps.wav (best model): Suprised\n",
            "Dự đoán cảm xúc YAF_void_neutral.wav (best model): Neutral\n",
            "Dự đoán cảm xúc a06.wav (best model): Neutral\n",
            "Dự đoán cảm xúc YAF_wag_neutral.wav (best model): Neutral\n",
            "Dự đoán cảm xúc a01.wav (best model): Neutral\n",
            "Dự đoán cảm xúc a05.wav (best model): Neutral\n",
            "Dự đoán cảm xúc YAF_walk_neutral.wav (best model): Neutral\n",
            "Dự đoán cảm xúc YAF_which_neutral.wav (best model): Neutral\n",
            "Dự đoán cảm xúc YAF_youth_neutral.wav (best model): Neutral\n",
            "Dự đoán cảm xúc d01.wav (best model): Neutral\n",
            "Dự đoán cảm xúc a02.wav (best model): Neutral\n",
            "Dự đoán cảm xúc a15.wav (best model): Neutral\n",
            "Dự đoán cảm xúc YAF_yes_neutral.wav (best model): Neutral\n",
            "Dự đoán cảm xúc YAF_tough_neutral.wav (best model): Neutral\n",
            "Dự đoán cảm xúc YAF_young_neutral.wav (best model): Neutral\n",
            "Dự đoán cảm xúc YAF_witch_neutral.wav (best model): Neutral\n",
            "Dự đoán cảm xúc YAF_whip_neutral.wav (best model): Neutral\n",
            "Dự đoán cảm xúc YAF_vine_neutral.wav (best model): Neutral\n",
            "Dự đoán cảm xúc YAF_week_neutral.wav (best model): Neutral\n",
            "Dự đoán cảm xúc a03.wav (best model): Neutral\n",
            "Dự đoán cảm xúc a04.wav (best model): Neutral\n",
            "Dự đoán cảm xúc YAF_white_neutral.wav (best model): Neutral\n",
            "Dự đoán cảm xúc YAF_vote_neutral.wav (best model): Neutral\n",
            "Dự đoán cảm xúc a14.wav (best model): Neutral\n",
            "Dự đoán cảm xúc YAF_wire_neutral.wav (best model): Neutral\n",
            "Dự đoán cảm xúc a10.wav (best model): Neutral\n",
            "Dự đoán cảm xúc YAF_turn_neutral.wav (best model): Neutral\n",
            "Dự đoán cảm xúc a08.wav (best model): Neutral\n",
            "Dự đoán cảm xúc d02.wav (best model): Neutral\n",
            "Dự đoán cảm xúc YAF_yearn_neutral.wav (best model): Neutral\n",
            "Dự đoán cảm xúc YAF_voice_neutral.wav (best model): Neutral\n",
            "Dự đoán cảm xúc YAF_wife_neutral.wav (best model): Neutral\n",
            "Dự đoán cảm xúc YAF_wash_neutral.wav (best model): Neutral\n",
            "Dự đoán cảm xúc d03.wav (best model): Neutral\n",
            "Dự đoán cảm xúc YAF_when_neutral.wav (best model): Neutral\n",
            "Dự đoán cảm xúc a12.wav (best model): Neutral\n",
            "Dự đoán cảm xúc a11.wav (best model): Neutral\n",
            "Dự đoán cảm xúc a07.wav (best model): Neutral\n",
            "Dự đoán cảm xúc a13.wav (best model): Neutral\n",
            "Dự đoán cảm xúc YAF_wheat_neutral.wav (best model): Neutral\n",
            "Dự đoán cảm xúc a09.wav (best model): Neutral\n",
            "Dự đoán cảm xúc YAF_sell_fear.wav (best model): Fearful\n",
            "Dự đoán cảm xúc YAF_wire_fear.wav (best model): Fearful\n",
            "Dự đoán cảm xúc YAF_size_fear.wav (best model): Fearful\n",
            "Dự đoán cảm xúc YAF_sub_fear.wav (best model): Fearful\n",
            "Dự đoán cảm xúc YAF_yes_fear.wav (best model): Fearful\n",
            "Dự đoán cảm xúc OAF_sour_fear.wav (best model): Fearful\n",
            "Dự đoán cảm xúc YAF_wag_fear.wav (best model): Fearful\n",
            "Dự đoán cảm xúc OAF_sub_fear.wav (best model): Fearful\n",
            "Dự đoán cảm xúc YAF_voice_fear.wav (best model): Fearful\n",
            "Dự đoán cảm xúc YAF_void_fear.wav (best model): Fearful\n",
            "Dự đoán cảm xúc YAF_yearn_fear.wav (best model): Fearful\n",
            "Dự đoán cảm xúc YAF_when_fear.wav (best model): Fearful\n",
            "Dự đoán cảm xúc YAF_time_fear.wav (best model): Fearful\n",
            "Dự đoán cảm xúc YAF_witch_fear.wav (best model): Fearful\n",
            "Dự đoán cảm xúc YAF_team_fear.wav (best model): Fearful\n",
            "Dự đoán cảm xúc YAF_white_fear.wav (best model): Fearful\n",
            "Dự đoán cảm xúc YAF_south_fear.wav (best model): Fearful\n",
            "Dự đoán cảm xúc YAF_vine_fear.wav (best model): Fearful\n",
            "Dự đoán cảm xúc YAF_sheep_fear.wav (best model): Fearful\n",
            "Dự đoán cảm xúc YAF_walk_fear.wav (best model): Fearful\n",
            "Dự đoán cảm xúc YAF_take_fear.wav (best model): Fearful\n",
            "Dự đoán cảm xúc YAF_youth_fear.wav (best model): Fearful\n",
            "Dự đoán cảm xúc YAF_week_fear.wav (best model): Fearful\n",
            "Dự đoán cảm xúc OAF_talk_fear.wav (best model): Fearful\n",
            "Dự đoán cảm xúc YAF_vote_fear.wav (best model): Fearful\n",
            "Dự đoán cảm xúc YAF_soup_fear.wav (best model): Fearful\n",
            "Dự đoán cảm xúc YAF_thin_fear.wav (best model): Fearful\n",
            "Dự đoán cảm xúc OAF_take_fear.wav (best model): Fearful\n",
            "Dự đoán cảm xúc YAF_young_fear.wav (best model): Fearful\n",
            "Dự đoán cảm xúc OAF_south_fear.wav (best model): Fearful\n",
            "Dự đoán cảm xúc YAF_tire_fear.wav (best model): Fearful\n",
            "Dự đoán cảm xúc YAF_tape_fear.wav (best model): Fearful\n",
            "Dự đoán cảm xúc YAF_shawl_fear.wav (best model): Fearful\n",
            "Dự đoán cảm xúc YAF_shack_fear.wav (best model): Fearful\n",
            "Dự đoán cảm xúc YAF_shout_fear.wav (best model): Fearful\n",
            "Dự đoán cảm xúc YAF_soap_fear.wav (best model): Fearful\n",
            "Dự đoán cảm xúc YAF_shirt_fear.wav (best model): Fearful\n",
            "Dự đoán cảm xúc OAF_sure_fear.wav (best model): Fearful\n",
            "Dự đoán cảm xúc YAF_should_fear.wav (best model): Fearful\n",
            "Dự đoán cảm xúc YAF_thought_fear.wav (best model): Fearful\n",
            "Dự đoán cảm xúc YAF_wheat_fear.wav (best model): Fearful\n",
            "Dự đoán cảm xúc YAF_which_fear.wav (best model): Fearful\n",
            "Dự đoán cảm xúc YAF_turn_fear.wav (best model): Fearful\n",
            "Dự đoán cảm xúc YAF_tip_fear.wav (best model): Fearful\n",
            "Dự đoán cảm xúc YAF_tough_fear.wav (best model): Fearful\n",
            "Dự đoán cảm xúc YAF_tool_fear.wav (best model): Fearful\n",
            "Dự đoán cảm xúc YAF_third_fear.wav (best model): Fearful\n",
            "Dự đoán cảm xúc YAF_sour_fear.wav (best model): Fearful\n",
            "Dự đoán cảm xúc YAF_whip_fear.wav (best model): Fearful\n",
            "Dự đoán cảm xúc YAF_shall_fear.wav (best model): Fearful\n",
            "Dự đoán cảm xúc YAF_such_fear.wav (best model): Fearful\n",
            "Dự đoán cảm xúc YAF_wife_fear.wav (best model): Fearful\n",
            "Dự đoán cảm xúc OAF_soup_fear.wav (best model): Fearful\n",
            "Dự đoán cảm xúc YAF_thumb_fear.wav (best model): Fearful\n",
            "Dự đoán cảm xúc OAF_such_fear.wav (best model): Fearful\n",
            "Dự đoán cảm xúc YAF_talk_fear.wav (best model): Fearful\n",
            "Dự đoán cảm xúc YAF_tell_fear.wav (best model): Fearful\n",
            "Dự đoán cảm xúc YAF_ton_fear.wav (best model): Fearful\n",
            "Dự đoán cảm xúc YAF_wash_fear.wav (best model): Fearful\n",
            "Dự đoán cảm xúc YAF_seize_fear.wav (best model): Fearful\n",
            "Dự đoán cảm xúc YAF_sure_fear.wav (best model): Fearful\n",
            "Dự đoán cảm xúc sa14.wav (best model): Sad\n",
            "Dự đoán cảm xúc su15.wav (best model): Sad\n",
            "Dự đoán cảm xúc sa01.wav (best model): Sad\n",
            "Dự đoán cảm xúc sa13.wav (best model): Sad\n",
            "Dự đoán cảm xúc su12.wav (best model): Sad\n",
            "Dự đoán cảm xúc su13.wav (best model): Sad\n",
            "Dự đoán cảm xúc su06.wav (best model): Sad\n",
            "Dự đoán cảm xúc sa15.wav (best model): Sad\n",
            "Dự đoán cảm xúc sa08.wav (best model): Sad\n",
            "Dự đoán cảm xúc su02.wav (best model): Sad\n",
            "Dự đoán cảm xúc su01.wav (best model): Sad\n",
            "Dự đoán cảm xúc sa10.wav (best model): Sad\n",
            "Dự đoán cảm xúc sa12.wav (best model): Sad\n",
            "Dự đoán cảm xúc sa04.wav (best model): Sad\n",
            "Dự đoán cảm xúc su08.wav (best model): Sad\n",
            "Dự đoán cảm xúc sa02.wav (best model): Sad\n",
            "Dự đoán cảm xúc sa06.wav (best model): Sad\n",
            "Dự đoán cảm xúc sa07.wav (best model): Sad\n",
            "Dự đoán cảm xúc su11.wav (best model): Sad\n",
            "Dự đoán cảm xúc su07.wav (best model): Sad\n",
            "Dự đoán cảm xúc sa09.wav (best model): Sad\n",
            "Dự đoán cảm xúc su09.wav (best model): Sad\n",
            "Dự đoán cảm xúc sa05.wav (best model): Sad\n",
            "Dự đoán cảm xúc sa11.wav (best model): Sad\n",
            "Dự đoán cảm xúc su03.wav (best model): Sad\n",
            "Dự đoán cảm xúc su04.wav (best model): Sad\n",
            "Dự đoán cảm xúc su05.wav (best model): Sad\n",
            "Dự đoán cảm xúc sa03.wav (best model): Sad\n",
            "Dự đoán cảm xúc su14.wav (best model): Sad\n",
            "Dự đoán cảm xúc su10.wav (best model): Sad\n",
            "Dự đoán cảm xúc OAF_sure_disgust.wav (best model): Disgusted\n",
            "Dự đoán cảm xúc OAF_team_disgust.wav (best model): Disgusted\n",
            "Dự đoán cảm xúc OAF_tire_disgust.wav (best model): Disgusted\n",
            "Dự đoán cảm xúc YAF_book_disgust.wav (best model): Disgusted\n",
            "Dự đoán cảm xúc OAF_whip_disgust.wav (best model): Disgusted\n",
            "Dự đoán cảm xúc OAF_time_disgust.wav (best model): Disgusted\n",
            "Dự đoán cảm xúc OAF_wire_disgust.wav (best model): Disgusted\n",
            "Dự đoán cảm xúc OAF_thumb_disgust.wav (best model): Disgusted\n",
            "Dự đoán cảm xúc OAF_wag_disgust.wav (best model): Disgusted\n",
            "Dự đoán cảm xúc YAF_boat_disgust.wav (best model): Disgusted\n",
            "Dự đoán cảm xúc OAF_tape_disgust.wav (best model): Disgusted\n",
            "Dự đoán cảm xúc OAF_tool_disgust.wav (best model): Disgusted\n",
            "Dự đoán cảm xúc OAF_thought_disgust.wav (best model): Disgusted\n",
            "Dự đoán cảm xúc OAF_tip_disgust.wav (best model): Disgusted\n",
            "Dự đoán cảm xúc OAF_shack_disgust.wav (best model): Disgusted\n",
            "Dự đoán cảm xúc OAF_shirt_disgust.wav (best model): Disgusted\n",
            "Dự đoán cảm xúc OAF_talk_disgust.wav (best model): Disgusted\n",
            "Dự đoán cảm xúc OAF_such_disgust.wav (best model): Disgusted\n",
            "Dự đoán cảm xúc OAF_said_disgust.wav (best model): Disgusted\n",
            "Dự đoán cảm xúc OAF_thin_disgust.wav (best model): Disgusted\n",
            "Dự đoán cảm xúc OAF_voice_disgust.wav (best model): Disgusted\n",
            "Dự đoán cảm xúc OAF_youth_disgust.wav (best model): Disgusted\n",
            "Dự đoán cảm xúc OAF_south_disgust.wav (best model): Disgusted\n",
            "Dự đoán cảm xúc OAF_tell_disgust.wav (best model): Disgusted\n",
            "Dự đoán cảm xúc OAF_tough_disgust.wav (best model): Disgusted\n",
            "Dự đoán cảm xúc YAF_bean_disgust.wav (best model): Disgusted\n",
            "Dự đoán cảm xúc OAF_third_disgust.wav (best model): Disgusted\n",
            "Dự đoán cảm xúc OAF_shall_disgust.wav (best model): Disgusted\n",
            "Dự đoán cảm xúc YAF_back_disgust.wav (best model): Disgusted\n",
            "Dự đoán cảm xúc YAF_bar_disgust.wav (best model): Disgusted\n",
            "Dự đoán cảm xúc OAF_sour_disgust.wav (best model): Disgusted\n",
            "Dự đoán cảm xúc OAF_yes_disgust.wav (best model): Disgusted\n",
            "Dự đoán cảm xúc YAF_bite_disgust.wav (best model): Disgusted\n",
            "Dự đoán cảm xúc OAF_wife_disgust.wav (best model): Disgusted\n",
            "Dự đoán cảm xúc OAF_sub_disgust.wav (best model): Disgusted\n",
            "Dự đoán cảm xúc OAF_soap_disgust.wav (best model): Disgusted\n",
            "Dự đoán cảm xúc OAF_search_disgust.wav (best model): Disgusted\n",
            "Dự đoán cảm xúc OAF_walk_disgust.wav (best model): Disgusted\n",
            "Dự đoán cảm xúc OAF_seize_disgust.wav (best model): Disgusted\n",
            "Dự đoán cảm xúc OAF_yearn_disgust.wav (best model): Disgusted\n",
            "Dự đoán cảm xúc OAF_week_disgust.wav (best model): Disgusted\n",
            "Dự đoán cảm xúc OAF_turn_disgust.wav (best model): Disgusted\n",
            "Dự đoán cảm xúc OAF_ton_disgust.wav (best model): Disgusted\n",
            "Dự đoán cảm xúc OAF_should_disgust.wav (best model): Disgusted\n",
            "Dự đoán cảm xúc YAF_base_disgust.wav (best model): Disgusted\n",
            "Dự đoán cảm xúc OAF_wheat_disgust.wav (best model): Disgusted\n",
            "Dự đoán cảm xúc YAF_bought_disgust.wav (best model): Disgusted\n",
            "Dự đoán cảm xúc YAF_bone_disgust.wav (best model): Disgusted\n",
            "Dự đoán cảm xúc OAF_take_disgust.wav (best model): Disgusted\n",
            "Dự đoán cảm xúc OAF_void_disgust.wav (best model): Disgusted\n",
            "Dự đoán cảm xúc OAF_shout_disgust.wav (best model): Disgusted\n",
            "Dự đoán cảm xúc OAF_sail_disgust.wav (best model): Disgusted\n",
            "Dự đoán cảm xúc OAF_vote_disgust.wav (best model): Disgusted\n",
            "Dự đoán cảm xúc OAF_witch_disgust.wav (best model): Disgusted\n",
            "Dự đoán cảm xúc OAF_size_disgust.wav (best model): Disgusted\n",
            "Dự đoán cảm xúc OAF_wash_disgust.wav (best model): Disgusted\n",
            "Dự đoán cảm xúc OAF_sell_disgust.wav (best model): Disgusted\n",
            "Dự đoán cảm xúc OAF_shawl_disgust.wav (best model): Disgusted\n",
            "Dự đoán cảm xúc YAF_bath_disgust.wav (best model): Disgusted\n",
            "Dự đoán cảm xúc OAF_which_disgust.wav (best model): Disgusted\n",
            "Dự đoán cảm xúc OAF_white_disgust.wav (best model): Disgusted\n",
            "Dự đoán cảm xúc OAF_sheep_disgust.wav (best model): Disgusted\n",
            "Dự đoán cảm xúc OAF_rush_disgust.wav (best model): Disgusted\n",
            "Dự đoán cảm xúc OAF_soup_disgust.wav (best model): Disgusted\n",
            "Dự đoán cảm xúc OAF_young_disgust.wav (best model): Disgusted\n",
            "Dự đoán cảm xúc OAF_when_disgust.wav (best model): Disgusted\n",
            "Dự đoán cảm xúc OAF_vine_disgust.wav (best model): Disgusted\n",
            "Dự đoán cảm xúc YAF_beg_disgust.wav (best model): Disgusted\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sa-IrJS1aRVJ"
      },
      "source": [
        "In order to use a GPU with your notebook, select the <code>Runtime &gt; Change runtime type</code> menu and then set the hardware accelerator to the desired option."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "65MSuHKqNeBZ"
      },
      "source": [
        "## More memory\n",
        "\n",
        "Users who have purchased one of Colab's paid plans have access to high-memory VMs when they are available. More powerful GPUs are always offered with high-memory VMs.\n",
        "You can see how much memory you have available at any time by running the following code cell. If the execution result of running the code cell below is 'Not using a high-RAM runtime', then you can enable a high-RAM runtime via <code>Runtime &gt; Change runtime type</code> in the menu. Then select High-RAM in the Runtime shape toggle button. After, re-execute the code cell."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V1G82GuO-tez"
      },
      "outputs": [],
      "source": [
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('Not using a high-RAM runtime')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BJW8Qi-pPpep"
      },
      "source": [
        "## Longer runtimes\n",
        "\n",
        "All Colab runtimes are reset after some period of time &#40;which is faster if the runtime isn't executing code&#41;. Colab Pro and Pro+ users have access to longer runtimes than those who use Colab free of charge.\n",
        "\n",
        "## Background execution\n",
        "\n",
        "Colab Pro+ users have access to background execution, where notebooks will continue executing even after you've closed a browser tab. This is always enabled in Pro+ runtimes as long as you have compute units available.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uLlTRcMM_h0k"
      },
      "source": [
        "## Relaxing resource limits in Colab Pro\n",
        "\n",
        "Your resources are not unlimited in Colab. To make the most of Colab, avoid using resources when you don't need them. For example, only use a GPU when required and close Colab tabs when finished.\n",
        "\n",
        "If you encounter limitations, you can relax those limitations by purchasing more compute units via pay as you go. Anyone can purchase compute units via <a href=\"https://colab.research.google.com/signup\">pay as you go</a>; no subscription is required."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mm8FzEidvPs6"
      },
      "source": [
        "## Send us feedback!\n",
        "\n",
        "<p>If you have any feedback for us, please let us know. The best way to send feedback is by using the Help &gt; 'Send feedback…' menu. If you encounter usage limits in Colab Pro consider subscribing to Pro+.</p>\n",
        "<p>If you encounter errors or other issues with billing &#40;payments&#41; for Colab Pro, Pro+ or pay as you go, please email <a href=\"mailto:colab-billing@google.com\">colab-billing@google.com</a>.</p>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qB3bdLe8jkAa"
      },
      "source": [
        "## More resources\n",
        "\n",
        "### Working with notebooks in Colab\n",
        "- [Overview of Colab](/notebooks/basic_features_overview.ipynb)\n",
        "- [Guide to markdown](/notebooks/markdown_guide.ipynb)\n",
        "- [Importing libraries and installing dependencies](/notebooks/snippets/importing_libraries.ipynb)\n",
        "- [Saving and loading notebooks in GitHub](https://colab.research.google.com/github/googlecolab/colabtools/blob/main/notebooks/colab-github-demo.ipynb)\n",
        "- [Interactive forms](/notebooks/forms.ipynb)\n",
        "- [Interactive widgets](/notebooks/widgets.ipynb)\n",
        "\n",
        "<a name=\"working-with-data\"></a>\n",
        "### Working with data\n",
        "- [Loading data: Drive, Sheets and Google Cloud Storage](/notebooks/io.ipynb)\n",
        "- [Charts: visualising data](/notebooks/charts.ipynb)\n",
        "- [Getting started with BigQuery](/notebooks/bigquery.ipynb)\n",
        "\n",
        "### Machine learning crash course\n",
        "These are a few of the notebooks from Google's online machine learning course. See the <a href=\"https://developers.google.com/machine-learning/crash-course/\">full course website</a> for more.\n",
        "- [Intro to Pandas DataFrame](https://colab.research.google.com/github/google/eng-edu/blob/main/ml/cc/exercises/pandas_dataframe_ultraquick_tutorial.ipynb)\n",
        "- [Linear regression with tf.keras using synthetic data](https://colab.research.google.com/github/google/eng-edu/blob/main/ml/cc/exercises/linear_regression_with_synthetic_data.ipynb)\n",
        "\n",
        "\n",
        "<a name=\"using-accelerated-hardware\"></a>\n",
        "### Using accelerated hardware\n",
        "- [TensorFlow with GPUs](/notebooks/gpu.ipynb)\n",
        "- [TPUs in Colab](/notebooks/tpu.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RFm2S0Gijqo8"
      },
      "source": [
        "<a name=\"machine-learning-examples\"></a>\n",
        "\n",
        "## Machine learning examples\n",
        "\n",
        "To see end-to-end examples of the interactive machine learning analyses that Colab makes possible, take a look at these tutorials using models from <a href=\"https://tfhub.dev\">TensorFlow Hub</a>.\n",
        "\n",
        "A few featured examples:\n",
        "\n",
        "- <a href=\"https://tensorflow.org/hub/tutorials/tf2_image_retraining\">Retraining an Image Classifier</a>: Build a Keras model on top of a pre-trained image classifier to distinguish flowers.\n",
        "- <a href=\"https://tensorflow.org/hub/tutorials/tf2_text_classification\">Text Classification</a>: Classify IMDB film reviews as either <em>positive</em> or <em>negative</em>.\n",
        "- <a href=\"https://tensorflow.org/hub/tutorials/tf2_arbitrary_image_stylization\">Style Transfer</a>: Use deep learning to transfer style between images.\n",
        "- <a href=\"https://tensorflow.org/hub/tutorials/retrieval_with_tf_hub_universal_encoder_qa\">Multilingual Universal Sentence Encoder Q&amp;A</a>: Use a machine-learning model to answer questions from the SQuAD dataset.\n",
        "- <a href=\"https://tensorflow.org/hub/tutorials/tweening_conv3d\">Video Interpolation</a>: Predict what happened in a video between the first and the last frame.\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Making the most of your colab subscription",
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}